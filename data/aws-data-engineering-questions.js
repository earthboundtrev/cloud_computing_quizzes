window.QUESTION_BANK_AWS_DATA_ENGINEERING = [
      // === DATA INGESTION & TRANSFORMATION ===
      { mode: "comparison", topic: "Ingestion",
        q: "For serverless ETL to extract, transform, and load data from various sources into S3 or databases, which service?",
        options: ["EC2 only", "AWS Glue", "Lambda only", "API Gateway"],
        correct: 1,
        explain: "AWS Glue = serverless ETL; crawlers, jobs, Data Catalog; Spark-based."
      },
      { mode: "comparison", topic: "Ingestion",
        q: "For real-time streaming data ingestion (e.g., logs, clickstreams), which AWS service?",
        options: ["S3 only", "Amazon Kinesis Data Streams or Kinesis Data Firehose", "Redshift", "RDS"],
        correct: 1,
        explain: "Kinesis Data Streams = real-time streaming. Kinesis Data Firehose = load into S3/Redshift/OpenSearch."
      },
      { mode: "comparison", topic: "Ingestion",
        q: "For migrating data from on-premises databases to AWS with minimal downtime, which service?",
        options: ["Glue only", "AWS DMS (Database Migration Service)", "Lambda", "Athena"],
        correct: 1,
        explain: "DMS = homogenous and heterogenous DB migration; CDC for ongoing replication."
      },
      { mode: "comparison", topic: "Transformation",
        q: "For running large-scale Spark, Hive, or Presto workloads on a managed cluster, which service?",
        options: ["Glue only", "Amazon EMR", "Lambda", "Athena"],
        correct: 1,
        explain: "EMR = managed Hadoop/Spark/Hive/Presto; big data processing at scale."
      },
      { mode: "exam", topic: "Ingestion",
        q: "What is the difference between Kinesis Data Streams and Kinesis Data Firehose?",
        options: ["They are identical", "Streams = real-time processing with consumers; Firehose = load directly to S3/Redshift etc.", "Firehose only", "Streams only"],
        correct: 1,
        explain: "Streams = real-time, consumers process. Firehose = fully managed, load to destinations; no custom consumers."
      },
      { mode: "exam", topic: "Transformation",
        q: "AWS Glue jobs can be authored in:",
        options: ["SQL only", "Python or Spark (PySpark/Spark SQL)", "Java only", "No code"],
        correct: 1,
        explain: "Glue jobs = Python (PySpark) or Spark SQL; generated or custom scripts."
      },
      { mode: "comparison", topic: "Transformation",
        q: "For orchestrating complex, multi-step data pipelines (Glue, EMR, Lambda, etc.), which service?",
        options: ["S3 Events only", "AWS Step Functions or EventBridge", "CloudWatch only", "SNS only"],
        correct: 1,
        explain: "Step Functions = workflow orchestration. EventBridge = event-driven; schedule Glue jobs."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Glue crawlers populate the Glue Data Catalog by:",
        options: ["Manual entry only", "Scanning data sources and inferring schema", "Copying data", "No catalog"],
        correct: 1,
        explain: "Crawlers scan S3, JDBC, etc.; infer schema; create/update tables in Data Catalog."
      },
      // === DATA STORE MANAGEMENT ===
      { mode: "comparison", topic: "Data Stores",
        q: "For a data lake, which storage is typically the primary repository for raw and processed data?",
        options: ["RDS", "Amazon S3", "DynamoDB", "ElastiCache"],
        correct: 1,
        explain: "S3 = data lake foundation; scalable, durable; store raw + processed data."
      },
      { mode: "comparison", topic: "Data Stores",
        q: "For interactive SQL queries on data in S3 without loading it into a database, which service?",
        options: ["Redshift only", "Amazon Athena", "RDS", "DynamoDB"],
        correct: 1,
        explain: "Athena = serverless SQL on S3; Pay per query; uses Glue Data Catalog or Hive metastore."
      },
      { mode: "comparison", topic: "Data Stores",
        q: "For a petabyte-scale cloud data warehouse with columnar storage and SQL analytics, which service?",
        options: ["RDS", "Amazon Redshift", "DynamoDB", "Athena"],
        correct: 1,
        explain: "Redshift = data warehouse; columnar; Massively Parallel Processing (MPP); SQL."
      },
      { mode: "comparison", topic: "Data Stores",
        q: "For centralized metadata and schema catalog across S3, Redshift, and Athena, which service?",
        options: ["RDS", "AWS Glue Data Catalog", "DynamoDB", "CloudWatch"],
        correct: 1,
        explain: "Glue Data Catalog = Hive-compatible metastore; tables, schemas; used by Glue, Athena, EMR."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Lake Formation helps with:",
        options: ["Only compute", "Data lake governance: access control, data catalog, encryption, audit", "Networking only", "Cost management only"],
        correct: 1,
        explain: "Lake Formation = secure data lakes; fine-grained access, catalog, encryption, audit trail."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift Serverless provides:",
        options: ["Only provisioned clusters", "Automatically scaled data warehouse; no cluster management", "No SQL", "Only DynamoDB"],
        correct: 1,
        explain: "Redshift Serverless = auto-provision; pay per RPU; no cluster sizing."
      },
      { mode: "comparison", topic: "Data Stores",
        q: "For low-latency key-value and document workloads at scale, which service?",
        options: ["Redshift", "Amazon DynamoDB", "RDS", "Athena"],
        correct: 1,
        explain: "DynamoDB = managed NoSQL; key-value and document; single-digit ms; serverless option."
      },
      { mode: "exam", topic: "Data Stores",
        q: "S3 Intelligent-Tiering moves objects between access tiers based on:",
        options: ["Manual only", "Access patterns; no retrieval fees when moving", "No movement", "Only to Glacier"],
        correct: 1,
        explain: "Intelligent-Tiering = auto-move between tiers based on access; no retrieval fee."
      },
      // === DATA OPERATIONS ===
      { mode: "exam", topic: "Operations",
        q: "Glue job bookmarks help with:",
        options: ["Only cost", "Incremental processing; track what data has been processed", "Security only", "Networking"],
        correct: 1,
        explain: "Job bookmarks = avoid reprocessing; track processed data; idempotent incremental loads."
      },
      { mode: "exam", topic: "Operations",
        q: "For monitoring Glue job runs, failures, and data quality, which services?",
        options: ["S3 only", "CloudWatch metrics, Glue console, Glue Data Quality", "Lambda only", "No monitoring"],
        correct: 1,
        explain: "CloudWatch = metrics/alarms. Glue Data Quality = rules, statistics, monitor quality."
      },
      { mode: "comparison", topic: "Operations",
        q: "For validating and improving data quality in Glue, which capability?",
        options: ["Crawlers only", "Glue Data Quality (rules, evaluations)", "Step Functions only", "SNS only"],
        correct: 1,
        explain: "Glue Data Quality = define rules; evaluate; integrate with ETL jobs."
      },
      { mode: "exam", topic: "Operations",
        q: "EMR cluster placement groups can improve:",
        options: ["Only cost", "Network performance (low latency between nodes)", "Storage only", "Security only"],
        correct: 1,
        explain: "Placement groups = collocate instances; lower latency for shuffle-heavy Spark jobs."
      },
      { mode: "exam", topic: "Operations",
        q: "For scheduling Glue jobs to run on a cron expression, which service is commonly used?",
        options: ["Lambda only", "EventBridge Scheduler or Glue Triggers", "S3 Events", "Step Functions only"],
        correct: 1,
        explain: "EventBridge Scheduler or Glue Triggers = schedule Glue jobs (cron, event-based)."
      },
      // === SECURITY & GOVERNANCE ===
      { mode: "exam", topic: "Security",
        q: "For encrypting S3 data at rest, which options are available?",
        options: ["No encryption", "SSE-S3, SSE-KMS, SSE-C (customer-provided keys)", "Only SSE-S3", "Only TLS"],
        correct: 1,
        explain: "SSE-S3 (AWS-managed), SSE-KMS, SSE-C (customer keys). Plus bucket policies for access."
      },
      { mode: "exam", topic: "Security",
        q: "Lake Formation uses which mechanism for fine-grained table and column access?",
        options: ["Only IAM", "IAM + LF-Tags and named resources (tables, columns)", "Security groups only", "NACLs only"],
        correct: 1,
        explain: "Lake Formation = LF-Tags, table/column grants; fine-grained access beyond IAM."
      },
      { mode: "exam", topic: "Security",
        q: "For auditing access to S3 buckets and Glue resources, which service?",
        options: ["S3 only", "CloudTrail (API calls) + S3 access logs", "Lambda only", "No audit"],
        correct: 1,
        explain: "CloudTrail = API auditing. S3 access logs = object-level access. Glue = CloudTrail."
      },
      { mode: "comparison", topic: "Security",
        q: "For secure connectivity from Glue to a VPC-resident database, which configuration?",
        options: ["Public endpoint only", "Glue connection with VPC, subnet, security group", "No VPC", "Internet only"],
        correct: 1,
        explain: "Glue connection = VPC, subnet, security group; access RDS, Redshift in VPC."
      },
      // === MORE ===
      { mode: "comparison", topic: "Ingestion",
        q: "For high-throughput file and object transfer from on-premises to S3 or EFS, which service?",
        options: ["DMS only", "AWS DataSync", "Lambda", "Athena"],
        correct: 1,
        explain: "DataSync = automated, accelerated transfer; S3, EFS, FSx; replication, scheduling."
      },
      { mode: "comparison", topic: "Transformation",
        q: "For serverless, event-driven transformation when new objects land in S3, which pattern?",
        options: ["EMR only", "S3 Event Notifications → Lambda or Glue", "Manual only", "Redshift only"],
        correct: 1,
        explain: "S3 events → Lambda (light) or Glue (heavy ETL); event-driven pipelines."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift Spectrum allows:",
        options: ["Only Redshift cluster storage", "Query data directly in S3 without loading into Redshift", "No S3", "DynamoDB only"],
        correct: 1,
        explain: "Redshift Spectrum = query S3 with Redshift SQL; external tables; no load needed."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Firehose can deliver to:",
        options: ["S3 only", "S3, Redshift, OpenSearch, Splunk, HTTP, Datadog, etc.", "DynamoDB only", "RDS only"],
        correct: 1,
        explain: "Firehose = S3, Redshift, OpenSearch, Splunk, custom HTTP; buffering, transforms."
      },
      { mode: "comparison", topic: "Data Stores",
        q: "For a fully managed, serverless SQL endpoint over S3 data lake with automatic scaling, which option?",
        options: ["Redshift provisioned only", "Athena or Redshift Serverless", "RDS", "DynamoDB"],
        correct: 1,
        explain: "Athena = serverless SQL on S3. Redshift Serverless = serverless warehouse."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue Dynamic Frames vs Spark DataFrames:",
        options: ["Identical", "Dynamic Frames handle schema flexibility; can convert to/from DataFrames", "No conversion", "Only Dynamic Frames"],
        correct: 1,
        explain: "Dynamic Frames = schema-on-read; flexible; resolve choice types; convert to Spark DataFrames."
      },
      { mode: "exam", topic: "Transformation",
        q: "EMR Serverless is suitable when:",
        options: ["Only long-lived clusters", "Spiky or variable Spark workloads; no cluster to manage", "No Spark", "Only Glue"],
        correct: 1,
        explain: "EMR Serverless = run Spark without clusters; pay per vCPU/memory; variable workloads."
      },
      { mode: "exam", topic: "Security",
        q: "For cross-account access to S3 data in a data lake, which approach?",
        options: ["Share access keys", "S3 Bucket policies + IAM roles (AssumeRole) or Lake Formation", "No cross-account", "Security groups only"],
        correct: 1,
        explain: "Bucket policy + IAM AssumeRole; or Lake Formation for fine-grained cross-account sharing."
      },
      { mode: "comparison", topic: "Ingestion",
        q: "For change data capture (CDC) from a source database to a data lake or warehouse, which service?",
        options: ["Glue crawlers only", "DMS (with ongoing replication / CDC)", "Lambda only", "Athena"],
        correct: 1,
        explain: "DMS = CDC; continuous replication of changes; homogenous or heterogenous."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Athena uses which metadata catalog by default?",
        options: ["Redshift", "AWS Glue Data Catalog (or Hive metastore)", "DynamoDB", "RDS"],
        correct: 1,
        explain: "Athena uses Glue Data Catalog by default; or external Hive metastore."
      },
      { mode: "exam", topic: "Operations",
        q: "For idempotent Glue ETL jobs that reprocess data safely, which practices help?",
        options: ["No idempotency", "Job bookmarks, overwrite by partition, deduplication logic", "Manual delete only", "No overwrite"],
        correct: 1,
        explain: "Job bookmarks + partition overwrites + dedupe = idempotent; safe reruns."
      },
      { mode: "comparison", topic: "Data Stores",
        q: "For a transactional data store with ACID and SQL, which AWS service?",
        options: ["S3 only", "Amazon RDS or Aurora", "DynamoDB for all cases", "Athena"],
        correct: 1,
        explain: "RDS/Aurora = relational, ACID, SQL; OLTP workloads."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Streams shards determine:",
        options: ["Only cost", "Throughput (records/sec, data/sec) and consumer parallelism", "Storage only", "Security only"],
        correct: 1,
        explain: "Shards = capacity units; 1000 records/sec, 1MB/sec per shard; scale by adding shards."
      },
      { mode: "exam", topic: "Security",
        q: "For encrypting Glue connection credentials (e.g., JDBC passwords), which service?",
        options: ["Plain text in Glue", "AWS Secrets Manager or Glue secure connection", "S3 bucket", "CloudWatch"],
        correct: 1,
        explain: "Secrets Manager or Glue secure connection = store credentials; no plain text."
      },
      { mode: "comparison", topic: "Transformation",
        q: "For real-time stream processing (e.g., aggregations, windowing) on Kinesis streams, which option?",
        options: ["Lambda only", "Kinesis Data Analytics (Flink or SQL)", "Glue only", "Athena"],
        correct: 1,
        explain: "Kinesis Data Analytics = real-time analytics; Flink or SQL; windowing, aggregations."
      },
      { mode: "exam", topic: "Data Stores",
        q: "S3 lifecycle policies can:",
        options: ["Only delete", "Transition to IA/Glacier and expire (delete) objects", "Only transition", "Only encrypt"],
        correct: 1,
        explain: "Lifecycle = transition (Standard → IA → Glacier) and expiration (delete)."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue workflow is used for:",
        options: ["Single job only", "Orchestrating multiple crawlers and jobs in a DAG", "No orchestration", "Lambda only"],
        correct: 1,
        explain: "Glue Workflows = DAG of crawlers and jobs; dependencies; triggers."
      },
      { mode: "comparison", topic: "Ingestion",
        q: "For ingesting data from SaaS applications (e.g., Salesforce, Marketo) into S3, which service?",
        options: ["DMS only", "AWS AppFlow", "Lambda only", "Glue only"],
        correct: 1,
        explain: "AppFlow = SaaS-to-AWS data flows; connectors for Salesforce, etc.; no code."
      },
      { mode: "exam", topic: "Transformation",
        q: "EMR vs Glue for ETL: Glue is preferred when:",
        options: ["Always use EMR", "Serverless, no cluster to manage; lighter workloads; integrated with Data Catalog", "No Glue", "Heavy custom Spark only"],
        correct: 1,
        explain: "Glue = serverless, managed; good for standard ETL. EMR = custom Spark, heavy compute, full control."
      },
      { mode: "exam", topic: "Security",
        q: "VPC endpoints for S3 and Glue help with:",
        options: ["Cost only", "Keeping traffic within AWS network; no public internet", "Latency only", "No benefit"],
        correct: 1,
        explain: "VPC endpoints = private connectivity to S3/Glue; no internet; better security, compliance."
      },
      { mode: "comparison", topic: "Data Stores",
        q: "For a search and analytics workload on semi-structured JSON logs, which service?",
        options: ["Redshift only", "Amazon OpenSearch Service", "DynamoDB for analytics", "RDS"],
        correct: 1,
        explain: "OpenSearch = search, log analytics; Elasticsearch-compatible; full-text, aggregations."
      },
      { mode: "exam", topic: "Operations",
        q: "For incremental data load from a JDBC source in Glue, which approach?",
        options: ["Full load only", "Job bookmarks + predicate pushdown (e.g., WHERE updated_at > last_run)", "No incremental", "Manual only"],
        correct: 1,
        explain: "Job bookmarks + predicate = incremental; avoid full scans; efficient."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift materialized views help with:",
        options: ["Only storage", "Pre-computed aggregates; faster repeated queries", "No views", "DynamoDB only"],
        correct: 1,
        explain: "Materialized views = stored results; refresh on schedule or manually; faster analytics."
      },
      { mode: "comparison", topic: "Ingestion",
        q: "For one-time large data migration (PB scale) with high latency tolerance, which option?",
        options: ["DataSync only", "AWS Snowball or Snowmobile", "DMS", "Glue"],
        correct: 1,
        explain: "Snowball/Snowmobile = offline transfer; ship device; for very large datasets."
      },
      { mode: "exam", topic: "Security",
        q: "Lake Formation LF-Tags are used for:",
        options: ["Only cost allocation", "Tag-based access control; grant access by tag", "No access control", "Encryption only"],
        correct: 1,
        explain: "LF-Tags = tag resources; grant permissions based on tags; attribute-based access."
      },
      // === TRIPLED: INGESTION & TRANSFORMATION ===
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Streams retention period can be set up to:",
        options: ["24 hours only", "8760 hours (365 days) for extended retention", "7 days only", "1 hour only"],
        correct: 1,
        explain: "Extended retention = up to 365 days; pay for storage; replay capability."
      },
      { mode: "comparison", topic: "Transformation",
        q: "Glue Spark job vs EMR Spark:",
        options: ["Identical", "Glue = serverless, no cluster; EMR = cluster, full control", "Only Glue", "Only EMR"],
        correct: 1,
        explain: "Glue = serverless Spark. EMR = you manage cluster; more tuning, longer-running jobs."
      },
      { mode: "exam", topic: "Ingestion",
        q: "DMS ongoing replication (CDC) requires:",
        options: ["Only full load", "Source with binary logs or similar (e.g., binlog for MySQL)", "No source config", "Only target"],
        correct: 1,
        explain: "CDC = enable binary logging on source; DMS reads changes continuously."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift concurrency scaling:",
        options: ["Not available", "Uses additional capacity for short bursts; no queue", "Only one query", "Only leader node"],
        correct: 1,
        explain: "Concurrency scaling = auto-add cluster capacity for burst; transparent to user."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue job run on failure can:",
        options: ["Only stop", "Notify SNS, trigger Lambda, or retry", "No action", "Only log"],
        correct: 1,
        explain: "On failure = SNS, Lambda, or Glue trigger; implement retry or alerting."
      },
      { mode: "comparison", topic: "Data Stores",
        q: "Athena workgroups allow:",
        options: ["Only one group", "Isolate queries, enforce limits, and track cost per workgroup", "No isolation", "Only Redshift"],
        correct: 1,
        explain: "Workgroups = separate query lists, result location, byte-scanned limits, cost per workgroup."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Firehose buffering is configured by:",
        options: ["Only size", "Size (MB) and interval (seconds); whichever is first", "Only interval", "No buffering"],
        correct: 1,
        explain: "Buffer = flush when size or time threshold is reached; tune for latency vs throughput."
      },
      { mode: "exam", topic: "Transformation",
        q: "EMR instance groups can be:",
        options: ["Only on-demand", "On-demand or Spot; core vs task nodes", "Only Spot", "Only core"],
        correct: 1,
        explain: "Master, core, task. Core = run HDFS. Task = no HDFS; scale compute. Spot for cost."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift RA3 nodes separate:",
        options: ["Nothing", "Compute and storage; scale independently", "Only compute", "Only storage"],
        correct: 1,
        explain: "RA3 = managed storage; pay for compute and storage separately; scale each."
      },
      { mode: "exam", topic: "Security",
        q: "Glue connection to a JDBC source in VPC requires:",
        options: ["Public IP only", "VPC, subnet, security group; optional NAT for S3/Glue", "No VPC", "Only security group"],
        correct: 1,
        explain: "Connection = VPC subnet, SG; Glue runs in your VPC to reach RDS/Redshift."
      },
      { mode: "exam", topic: "Ingestion",
        q: "AppFlow supports:",
        options: ["Only S3", "S3, Redshift, Salesforce, Marketo, etc.; scheduled or event", "Only Salesforce", "Only on-prem"],
        correct: 1,
        explain: "AppFlow = SaaS connectors; flow to S3/Redshift; schedule or trigger."
      },
      { mode: "exam", topic: "Transformation",
        q: "Glue Spark job worker type can be:",
        options: ["Only G.1X", "G.1X, G.2X, Z.2X (for Ray); scale by DPU", "Only Z.2X", "Only standard"],
        correct: 1,
        explain: "Worker type = G.1X (1 DPU), G.2X (2 DPU), Z.2X for Ray; more DPU = more memory/CPU."
      },
      { mode: "exam", topic: "Data Stores",
        q: "DynamoDB Streams enable:",
        options: ["Only backup", "Change capture; trigger Lambda or replicate", "Only queries", "Only scans"],
        correct: 1,
        explain: "Streams = ordered change stream; Lambda, Kinesis, or cross-region replication."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue Data Quality rules can:",
        options: ["Only log", "Evaluate dataset; fail job or alert if rules fail", "Only pass", "No rules"],
        correct: 1,
        explain: "Data Quality = define rules; run with job; optional stop on failure or alert."
      },
      { mode: "comparison", topic: "Ingestion",
        q: "DataSync vs Snowball:",
        options: ["Same thing", "DataSync = network transfer; Snowball = offline for very large", "Only Snowball", "Only DataSync"],
        correct: 1,
        explain: "DataSync = over network. Snowball = ship device for PB-scale or poor connectivity."
      },
      { mode: "exam", topic: "Transformation",
        q: "Kinesis Data Analytics SQL can:",
        options: ["Only filter", "Filter, aggregate, window (tumbling, sliding); write to Kinesis or Lambda", "Only write to S3", "No SQL"],
        correct: 1,
        explain: "Kinesis Data Analytics = SQL or Flink; real-time aggregation, windowing; sink to stream or Lambda."
      },
      { mode: "exam", topic: "Data Stores",
        q: "S3 Select allows:",
        options: ["Only full object read", "Retrieve subset of object (SQL-like); less data transfer", "Only CSV", "Only Parquet"],
        correct: 1,
        explain: "S3 Select = SQL expression on object; reduce bytes transferred; CSV, JSON, Parquet."
      },
      { mode: "exam", topic: "Security",
        q: "Redshift encryption at rest uses:",
        options: ["Only default key", "AWS default or customer KMS key", "No encryption", "Only TLS"],
        correct: 1,
        explain: "Redshift = encrypt with AWS or CMK; enable at cluster creation."
      },
      { mode: "exam", topic: "Ingestion",
        q: "DMS task settings can include:",
        options: ["Only full load", "Full load, CDC, target table prep (truncate, drop)", "Only CDC", "No settings"],
        correct: 1,
        explain: "Task = full load and/or CDC; target table prep; mapping rules; tuning parameters."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Athena partition projection:",
        options: ["No partitions", "Define partition schema in table; no need to add partitions manually", "Only Hive partitions", "Only S3"],
        correct: 1,
        explain: "Partition projection = table metadata defines partition layout; no MSCK REPAIR."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue trigger types include:",
        options: ["Only schedule", "On-demand, schedule, event (e.g., job success)", "Only event", "Only on-demand"],
        correct: 1,
        explain: "Trigger = on-demand, schedule (cron), or event (e.g., when job X completes)."
      },
      { mode: "exam", topic: "Transformation",
        q: "EMR managed scaling:",
        options: ["Manual only", "Auto add/remove task nodes based on YARN metrics", "Only add", "Only remove"],
        correct: 1,
        explain: "Managed scaling = scale task nodes; based on pending memory/vCPU; min/max units."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift Spectrum external table:",
        options: ["Stored in Redshift", "Metadata in Redshift; data in S3", "Only S3", "Only Redshift"],
        correct: 1,
        explain: "Spectrum = external table points to S3; query with Redshift SQL; no load."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Streams enhanced fan-out:",
        options: ["Not available", "Dedicated 2 MB/s per consumer; lower latency", "Only 1 consumer", "Only standard fan-out"],
        correct: 1,
        explain: "Enhanced fan-out = dedicated throughput per consumer; no shared read limit."
      },
      { mode: "exam", topic: "Security",
        q: "Glue resource policies allow:",
        options: ["Only same account", "Cross-account access to catalog, jobs", "No cross-account", "Only IAM"],
        correct: 1,
        explain: "Resource policy on Glue = allow other accounts to access catalog/jobs; IAM in other account."
      },
      { mode: "exam", topic: "Transformation",
        q: "Glue flexible streaming (Spark Structured Streaming):",
        options: ["Not supported", "Supported; read from Kinesis/Kafka, write to S3/catalog", "Only batch", "Only Kinesis"],
        correct: 1,
        explain: "Glue streaming = Spark Structured Streaming; Kinesis or Kafka source; micro-batch."
      },
      { mode: "exam", topic: "Data Stores",
        q: "DynamoDB global tables provide:",
        options: ["Only single region", "Multi-region replication; active-active", "Only backup", "Only stream"],
        correct: 1,
        explain: "Global tables = multi-region, eventually consistent replication; active-active writes."
      },
      { mode: "exam", topic: "Operations",
        q: "Redshift maintenance window:",
        options: ["Not configurable", "Set weekly window for updates and patches", "Only manual", "Only automatic"],
        correct: 1,
        explain: "Maintenance window = when Redshift can apply updates; avoid peak hours."
      },
      { mode: "exam", topic: "Ingestion",
        q: "DMS schema conversion:",
        options: ["Not supported", "Convert source schema to target (e.g., Oracle to Aurora)", "Only same engine", "Only full load"],
        correct: 1,
        explain: "DMS SCT or built-in = convert schema for heterogenous migration."
      },
      { mode: "exam", topic: "Data Stores",
        q: "OpenSearch Serverless is suitable for:",
        options: ["Only relational", "Log analytics, search; no cluster to manage", "Only DynamoDB", "Only Redshift"],
        correct: 1,
        explain: "OpenSearch Serverless = search and log analytics; auto scaling; OCU-based."
      },
      { mode: "exam", topic: "Transformation",
        q: "Glue job timeout:",
        options: ["No timeout", "Configurable (e.g., 2880 min); job stopped if exceeded", "Only 1 hour", "Only 24 hours"],
        correct: 1,
        explain: "Job run timeout = stop job after N minutes; avoid runaway jobs."
      },
      { mode: "exam", topic: "Security",
        q: "Lake Formation data cell filters:",
        options: ["Only table level", "Row/column filter; restrict which rows/columns a principal sees", "No filters", "Only column"],
        correct: 1,
        explain: "Data cell filters = row-level or column-level; grant with filter; fine-grained."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Streams partition key:",
        options: ["Only one key", "Determines shard; same key goes to same shard", "Random", "No key"],
        correct: 1,
        explain: "Partition key = hashed to shard; same key = same shard; ordering per key."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift VACUUM:",
        options: ["Only delete", "Reclaim space and sort rows after DELETE/UPDATE", "Only sort", "Only analyze"],
        correct: 1,
        explain: "VACUUM = reclaim space from deleted rows; optionally re-sort. ANALYZE = update stats."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue development endpoint:",
        options: ["Only production", "Interactive dev environment; test scripts before job", "No dev", "Only notebook"],
        correct: 1,
        explain: "Dev endpoint = long-lived environment; run and debug Glue jobs interactively."
      },
      { mode: "exam", topic: "Transformation",
        q: "EMR release version:",
        options: ["Only latest", "Choose release (e.g., emr-6.x) with specific applications", "Only 5.x", "Only 6.x"],
        correct: 1,
        explain: "Release = emr-6.x, 5.x, etc.; select applications (Spark, Hive, etc.)."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Athena query result location:",
        options: ["Only in-memory", "S3 bucket; configurable per workgroup", "Only workgroup default", "No S3"],
        correct: 1,
        explain: "Results = S3 path; set per workgroup or per query; pay for storage."
      },
      { mode: "exam", topic: "Ingestion",
        q: "DMS change processing order (full load + CDC):",
        options: ["CDC first", "Full load first, then CDC for ongoing changes", "Only full load", "Only CDC"],
        correct: 1,
        explain: "Full load = initial copy. Then CDC = apply changes; order preserved."
      },
      { mode: "exam", topic: "Security",
        q: "Redshift column-level security:",
        options: ["Not supported", "GRANT on specific columns; restrict column access", "Only row", "Only table"],
        correct: 1,
        explain: "GRANT SELECT (col1, col2) = column-level; user sees only those columns."
      },
      { mode: "exam", topic: "Transformation",
        q: "Glue job number of workers:",
        options: ["Fixed", "Set min/max or exact; scale with data size", "Only 1", "Only 10"],
        correct: 1,
        explain: "NumberOfWorkers or WorkerType + NumberOfWorkers; scale for parallelism."
      },
      { mode: "exam", topic: "Data Stores",
        q: "S3 Object Lock:",
        options: ["Only versioning", "WORM; retain objects for compliance", "No retention", "Only lifecycle"],
        correct: 1,
        explain: "Object Lock = WORM; compliance or governance mode; retain for period."
      },
      { mode: "exam", topic: "Operations",
        q: "Redshift WLM (Workload Management):",
        options: ["No queues", "Query queues; priority and concurrency per queue", "Only one queue", "Only automatic"],
        correct: 1,
        explain: "WLM = define queues (e.g., reporting vs ETL); concurrency, memory, timeout."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Firehose transformation:",
        options: ["No transform", "Lambda to transform records before delivery", "Only in destination", "Only batch"],
        correct: 1,
        explain: "Firehose = optional Lambda; transform in-flight before S3/Redshift/etc."
      },
      { mode: "exam", topic: "Data Stores",
        q: "DynamoDB DAX is used for:",
        options: ["Only write", "Caching; microsecond read latency", "Only global tables", "Only streams"],
        correct: 1,
        explain: "DAX = in-memory cache; read-through; sub-ms reads for key-value."
      },
      { mode: "exam", topic: "Transformation",
        q: "EMR step:",
        options: ["Only one per cluster", "Submit job (Spark, Hive, etc.) as step; multiple steps", "Only Spark", "Only Hive"],
        correct: 1,
        explain: "Step = unit of work (Spark, Hive, etc.); run sequentially or in parallel; cluster can run many."
      },
      { mode: "exam", topic: "Security",
        q: "Athena workgroup encryption:",
        options: ["Not configurable", "Override result encryption (SSE-S3 or SSE-KMS)", "Only S3 default", "No encryption"],
        correct: 1,
        explain: "Workgroup = can set encryption for query results in S3."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift distribution key:",
        options: ["Only AUTO", "EVEN, KEY, or ALL; affects data placement", "Only KEY", "Only ALL"],
        correct: 1,
        explain: "Distribution = EVEN (round-robin), KEY (col), ALL (replicate); tune for joins."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue catalog table versioning:",
        options: ["Not supported", "Table version = immutable snapshot; time travel", "Only current", "Only S3 versioning"],
        correct: 1,
        explain: "Table version = point-in-time; query historical version; governance."
      },
      { mode: "exam", topic: "Ingestion",
        q: "DMS validation:",
        options: ["Not available", "Compare source and target row counts or full validation", "Only count", "Only full"],
        correct: 1,
        explain: "Validation = verify replication; full or count-only; resume if failed."
      },
      { mode: "exam", topic: "Transformation",
        q: "Glue Spark shuffle partitions:",
        options: ["Fixed 200", "Configurable; more = smaller partitions, more overhead", "Only 1", "Only 1000"],
        correct: 1,
        explain: "spark.sql.shuffle.partitions = tune for join/aggregation; balance parallelism and overhead."
      },
      { mode: "exam", topic: "Data Stores",
        q: "S3 Replication (CRR/SRR):",
        options: ["Only same region", "Cross-region or same-region; replicate new objects", "Only CRR", "Only SRR"],
        correct: 1,
        explain: "CRR = cross-region. SRR = same region. Replicate to another bucket; optional delete replication."
      },
      { mode: "exam", topic: "Operations",
        q: "Redshift resize:",
        options: ["Not supported", "Change node type or count; elastic resize or classic", "Only elastic", "Only classic"],
        correct: 1,
        explain: "Resize = change cluster size; elastic (faster) or classic; may require downtime for classic."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Streams iterator:",
        options: ["Only latest", "TRIM_HORIZON (oldest) or LATEST (new only)", "Only trim", "No iterator"],
        correct: 1,
        explain: "GetRecords = TRIM_HORIZON (from start) or AFTER_SEQUENCE_NUMBER (from position)."
      },
      { mode: "exam", topic: "Security",
        q: "Glue Data Catalog encryption:",
        options: ["Not supported", "Encrypt catalog with KMS", "Only S3", "Only at rest"],
        correct: 1,
        explain: "Glue Data Catalog = encrypt with KMS; enable in settings."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Athena CTAS (Create Table As Select):",
        options: ["Only to Redshift", "Create table in S3 (e.g., Parquet) from query", "Only to DynamoDB", "Only CSV"],
        correct: 1,
        explain: "CTAS = create external table and write query results to S3; format, partitioning."
      },
      { mode: "exam", topic: "Transformation",
        q: "EMR security configuration:",
        options: ["Only IAM", "Encryption (in-transit, at rest), Kerberos optional", "No encryption", "Only Kerberos"],
        correct: 1,
        explain: "Security config = encryption for EBS, S3, in-transit; optional Kerberos."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift sort key:",
        options: ["Only one column", "COMPOUND or INTERLEAVED; improves range query performance", "Only compound", "Only interleaved"],
        correct: 1,
        explain: "Sort key = physical order; compound = one order; interleaved = multi-column equality."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue job continuous logging:",
        options: ["Not available", "Stream driver logs to CloudWatch during run", "Only at end", "Only to S3"],
        correct: 1,
        explain: "Continuous logging = CloudWatch log stream; see logs while job runs."
      },
      { mode: "exam", topic: "Ingestion",
        q: "DMS SCT (Schema Conversion Tool):",
        options: ["Only DMS", "Standalone tool; convert schema for heterogenous migration", "Only homogenous", "Only target"],
        correct: 1,
        explain: "SCT = convert schema (e.g., Oracle to PostgreSQL); run separately from DMS task."
      },
      { mode: "exam", topic: "Data Stores",
        q: "DynamoDB point-in-time recovery:",
        options: ["Not supported", "Continuous backup; restore to any point in last 35 days", "Only 7 days", "Only manual backup"],
        correct: 1,
        explain: "PITR = continuous backup; restore to new table; 35-day window."
      },
      { mode: "exam", topic: "Transformation",
        q: "Glue Python shell job:",
        options: ["Not supported", "Single node; small ETL or orchestration", "Only Spark", "Only Ray"],
        correct: 1,
        explain: "Python shell = 1 DPU; Python only; light workloads, no Spark."
      },
      { mode: "exam", topic: "Security",
        q: "Redshift audit logging:",
        options: ["Not available", "Log connections, queries to S3 or CloudWatch", "Only CloudWatch", "Only S3"],
        correct: 1,
        explain: "Enable audit logging = connection, user, query logs; S3 or CloudWatch."
      },
      { mode: "exam", topic: "Data Stores",
        q: "OpenSearch index:",
        options: ["Only one per domain", "Many indices; shards and replicas per index", "Only one shard", "No replicas"],
        correct: 1,
        explain: "Index = logical namespace; primary shards + replicas; scale per index."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue job cost is driven by:",
        options: ["Only job count", "DPU × run time; billed per second", "Only run time", "Only DPU"],
        correct: 1,
        explain: "Glue = pay for DPU-seconds; more workers/longer = more cost."
      },
      { mode: "exam", topic: "Ingestion",
        q: "DataSync task schedule:",
        options: ["Only once", "One-time or recurring (hourly, daily, etc.)", "Only daily", "Only manual"],
        correct: 1,
        explain: "DataSync = schedule task; run once or recurring; filter by include/exclude."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift UNLOAD:",
        options: ["Only to Redshift", "Export query result to S3 (Parquet, CSV, etc.)", "Only CSV", "Only one file"],
        correct: 1,
        explain: "UNLOAD = export to S3; parallel; Parquet or delimited; optional partition."
      },
      { mode: "exam", topic: "Transformation",
        q: "Kinesis Data Analytics application:",
        options: ["Only Flink", "Flink or SQL; run in Kinesis Data Analytics", "Only SQL", "Only Lambda"],
        correct: 1,
        explain: "Kinesis Data Analytics = Flink (Java/Scala) or SQL; managed; scale automatically."
      },
      { mode: "exam", topic: "Security",
        q: "Lake Formation permission model:",
        options: ["Only IAM", "IAM + Lake Formation (LF grants override for catalog resources)", "Only LF", "No catalog"],
        correct: 1,
        explain: "LF = grant on Data Catalog resources; can use LF only (no IAM on data) or hybrid."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Athena federated query:",
        options: ["Only S3", "Connect to RDS, DynamoDB, etc. via connector (Lambda)", "Only Redshift", "No connectors"],
        correct: 1,
        explain: "Federated query = Lambda connector; query RDS, DynamoDB, etc. from Athena."
      },
      { mode: "exam", topic: "Operations",
        q: "EMR cluster termination protection:",
        options: ["Always on", "Optional; prevent accidental terminate", "Not available", "Only for master"],
        correct: 1,
        explain: "Termination protection = cannot terminate cluster until disabled; avoid accidental loss."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Glue crawler schedule:",
        options: ["Only on-demand", "On-demand or cron schedule", "Only daily", "Only event"],
        correct: 1,
        explain: "Crawler = run on-demand or on schedule; keep catalog in sync with S3/DB."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift concurrency scaling is billed:",
        options: ["Included free", "Separate charge when used (per second)", "Only per query", "Only per cluster"],
        correct: 1,
        explain: "Concurrency scaling = pay for extra capacity when used; per second."
      },
      { mode: "exam", topic: "Transformation",
        q: "Glue job Spark UI:",
        options: ["Not available", "Enable in job; view in Spark history (S3 or Glue)", "Only S3", "Only CloudWatch"],
        correct: 1,
        explain: "Spark UI = enable in job; logs to S3; view stages, tasks, skew."
      },
      { mode: "exam", topic: "Security",
        q: "DMS replication instance in VPC:",
        options: ["Not supported", "Place in VPC to reach source/target privately", "Only public", "Only target"],
        correct: 1,
        explain: "Replication instance in VPC = access RDS, EC2 DB in same VPC; no public internet."
      },
      { mode: "exam", topic: "Data Stores",
        q: "S3 batch operations:",
        options: ["Only copy", "Bulk actions: copy, restore, invalidation, etc.", "Only restore", "Only delete"],
        correct: 1,
        explain: "Batch Operations = run single action on many objects; copy, restore, Lambda, etc."
      },
      { mode: "exam", topic: "Operations",
        q: "Redshift snapshot:",
        options: ["Only manual", "Manual or automated (retention period); restore to new cluster", "Only automated", "Only 1 day"],
        correct: 1,
        explain: "Snapshot = backup; manual or automated (e.g., 8-day retention); cross-region copy optional."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Streams resharding:",
        options: ["Not supported", "Split or merge shards; adjust capacity", "Only split", "Only merge"],
        correct: 1,
        explain: "Split = 1 shard → 2. Merge = 2 → 1. Adjust to throughput needs; keys repartitioned."
      },
      { mode: "exam", topic: "Transformation",
        q: "Glue job metrics:",
        options: ["Only success", "Duration, DPU, records; in CloudWatch", "Only CloudWatch", "Only duration"],
        correct: 1,
        explain: "Glue emits metrics: job duration, DPU, records read/written; CloudWatch."
      },
      { mode: "exam", topic: "Data Stores",
        q: "DynamoDB auto scaling:",
        options: ["Manual only", "Scale read/write capacity on target utilization", "Only read", "Only write"],
        correct: 1,
        explain: "Auto scaling = target utilization %; scale RCU/WCU; min/max capacity."
      },
      { mode: "exam", topic: "Security",
        q: "Athena and VPC:",
        options: ["Athena in VPC", "Athena runs in AWS; use VPC endpoint for private S3 access", "No VPC", "Only S3 endpoint"],
        correct: 1,
        explain: "Athena in AWS; your VPC endpoint for S3 = private access to data in S3."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift data sharing:",
        options: ["Not supported", "Share datashares with other clusters/accounts (read-only)", "Only same account", "Only same cluster"],
        correct: 1,
        explain: "Datashare = share database/schema to other Redshift (same or cross-account); read-only."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue job retry:",
        options: ["No retry", "Configurable retries (e.g., 1) for transient failures", "Only 1", "Infinite"],
        correct: 1,
        explain: "Job run retry = retry on failure; set number; exponential backoff optional."
      },
      { mode: "exam", topic: "Ingestion",
        q: "DMS source endpoint for S3:",
        options: ["Not supported", "S3 as source for full load (e.g., CSV); not for CDC", "Only CDC", "Only target"],
        correct: 1,
        explain: "S3 as source = full load from files; not change data capture."
      },
      { mode: "exam", topic: "Data Stores",
        q: "OpenSearch index lifecycle management:",
        options: ["Not available", "Automate rollover, shrink, delete by age/size", "Only rollover", "Only delete"],
        correct: 1,
        explain: "ILM = policy: hot → warm → cold → delete; rollover by size/age."
      },
      { mode: "exam", topic: "Transformation",
        q: "EMR file system (EMRFS):",
        options: ["Only HDFS", "S3 with consistency (list/read); optional EMRFS metadata", "Only S3 direct", "No S3"],
        correct: 1,
        explain: "EMRFS = S3 as file system; consistent view; optional metadata for list consistency."
      },
      { mode: "exam", topic: "Security",
        q: "Redshift SSL connection:",
        options: ["Not supported", "Encrypt in transit; require SSL in cluster config", "Only optional", "Only for admin"],
        correct: 1,
        explain: "Cluster parameter require_ssl = true; clients use SSL to connect."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Lake Formation grantable permissions:",
        options: ["No grantable", "Grant and allow grantee to grant to others", "Only table", "Only database"],
        correct: 1,
        explain: "Grantable = with grant option; delegate permission to others (e.g., department admin)."
      },
      { mode: "exam", topic: "Operations",
        q: "Glue job timeout (job run):",
        options: ["No timeout", "Timeout in minutes; stop run if exceeded", "Only 60 min", "Only 24 hours"],
        correct: 1,
        explain: "Timeout = max run time per job run; avoid runaway; configurable."
      },
      { mode: "exam", topic: "Ingestion",
        q: "Kinesis Data Firehose delivery stream name:",
        options: ["Any format", "Alphanumeric, hyphen; unique per account/region", "Only numeric", "No constraint"],
        correct: 1,
        explain: "Stream name = alphanumeric, hyphen; unique; immutable after create."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Redshift superuser:",
        options: ["Only one", "Has all privileges; use for admin; avoid for apps", "No superuser", "Only for restore"],
        correct: 1,
        explain: "Superuser = bypass all checks; use for admin tasks; least privilege for apps."
      },
      { mode: "exam", topic: "Transformation",
        q: "Glue job bookmark for JDBC:",
        options: ["Not supported", "Track last processed value (e.g., column); incremental", "Only S3", "Only full"],
        correct: 1,
        explain: "Job bookmark with JDBC = track column (e.g., id or timestamp); next run continues from last."
      },
      { mode: "exam", topic: "Security",
        q: "S3 access points:",
        options: ["Only bucket", "Named access with policy; delegate access to bucket subset", "Only IAM", "No policy"],
        correct: 1,
        explain: "Access point = name + policy; grant access to shared bucket with restricted policy."
      },
      { mode: "exam", topic: "Data Stores",
        q: "Athena query cache:",
        options: ["Not available", "Reuse result for same query (within 24h); reduce cost", "Only 1 hour", "Only same workgroup"],
        correct: 1,
        explain: "Result reuse = cache result; same query within period = no charge; workgroup setting."
      },
      { mode: "exam", topic: "Operations",
        q: "Redshift restore from snapshot:",
        options: ["Only same cluster", "Create new cluster from snapshot; point-in-time", "Only automated snapshot", "Only manual"],
        correct: 1,
        explain: "Restore = new cluster from snapshot; optional point-in-time (automated snapshot)."
      },
      { mode: "exam", topic: "Ingestion",
        q: "AppFlow error handling:",
        options: ["Only stop", "Retry, log to S3, or continue on error", "No retry", "Only log"],
        correct: 1,
        explain: "Flow can retry, write failed records to S3, or continue; configurable."
      },
      { mode: "exam", topic: "Transformation",
        q: "EMR instance fleet:",
        options: ["Not available", "Mix instance types (e.g., Spot + on-demand); cost optimization", "Only one type", "Only Spot"],
        correct: 1,
        explain: "Instance fleet = multiple instance types; Spot + on-demand; lower cost."
      },
      { mode: "exam", topic: "Data Stores",
        q: "DynamoDB global secondary index (GSI):",
        options: ["Only one", "Multiple GSIs; different partition/sort key; eventually consistent", "Only same key", "Only strongly consistent"],
        correct: 1,
        explain: "GSI = alternate partition/sort key; eventually consistent; separate throughput or on-demand."
      },
    ];
