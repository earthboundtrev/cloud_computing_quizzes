window.QUESTION_BANK_AWS_MLEA = [
      // === DATA PREPARATION ===
      { mode: "comparison", topic: "Data Preparation",
        q: "Which SageMaker component helps with data cleaning, transformation, and feature engineering in a visual interface?",
        options: ["SageMaker Ground Truth", "SageMaker Data Wrangler", "SageMaker Feature Store", "SageMaker Pipelines"],
        correct: 1,
        explain: "SageMaker Data Wrangler = visual data prep; connect to S3/Athena/Redshift, clean, transform, feature engineer."
      },
      { mode: "comparison", topic: "Data Preparation",
        q: "For storing and serving ML features at low latency for training and inference, which service?",
        options: ["S3 only", "SageMaker Feature Store", "DynamoDB only", "Redshift"],
        correct: 1,
        explain: "SageMaker Feature Store = centralized feature repo; online (low-latency inference) and offline (training) stores."
      },
      { mode: "comparison", topic: "Data Preparation",
        q: "Which data format is commonly used for ML training data due to columnar storage and schema preservation?",
        options: ["CSV only", "JSON only", "Parquet", "Plain text"],
        correct: 2,
        explain: "Parquet = columnar, compressed, schema-preserving; efficient for ML. Also: ORC, Avro."
      },
      { mode: "comparison", topic: "Data Preparation",
        q: "For ingesting real-time streaming data into an ML pipeline, which AWS service?",
        options: ["S3 only", "Amazon Kinesis Data Streams", "Redshift", "Athena"],
        correct: 1,
        explain: "Kinesis Data Streams = real-time streaming; Kinesis Data Firehose for delivery to S3/Redshift."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "A team stores training data in S3 as CSV. For SageMaker training, what is a best practice?",
        options: ["Use CSV as-is for all workloads", "Convert to Parquet or RecordIO for efficiency", "Store only in RDS", "Use EBS volumes only"],
        correct: 1,
        explain: "Parquet or RecordIO (Protobuf) improves I/O and compression. CSV works but is less efficient at scale."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Data Wrangler can export data preparation steps as what?",
        options: ["Only manual notebooks", "SageMaker Pipelines flow (or Python script)", "Lambda functions only", "Step Functions only"],
        correct: 1,
        explain: "Data Wrangler exports to Pipelines or Python for automation in production."
      },
      // === MODEL DEVELOPMENT ===
      { mode: "comparison", topic: "Model Development",
        q: "Which SageMaker feature automates model building with minimal code for tabular, vision, and NLP?",
        options: ["SageMaker Training Jobs only", "SageMaker Autopilot", "SageMaker Inference", "SageMaker Pipelines only"],
        correct: 1,
        explain: "SageMaker Autopilot = automated ML; data prep, algorithm selection, hyperparameter tuning, deploy."
      },
      { mode: "comparison", topic: "Model Development",
        q: "For hyperparameter tuning across many training jobs in parallel, which SageMaker capability?",
        options: ["Single training job", "SageMaker Hyperparameter Tuning Jobs", "Manual scripting only", "Lambda"],
        correct: 1,
        explain: "Hyperparameter Tuning Jobs = run many training jobs in parallel; Bayesian or random search."
      },
      { mode: "comparison", topic: "Model Development",
        q: "Where do you register and version ML models for deployment and lineage?",
        options: ["S3 buckets only", "SageMaker Model Registry", "DynamoDB", "RDS"],
        correct: 1,
        explain: "SageMaker Model Registry = catalog models, version, approve for deployment, lineage."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker distributed training can use which strategies?",
        options: ["Single node only", "Data parallel and model parallel", "Only model parallel", "Only data parallel"],
        correct: 1,
        explain: "Data parallel = split data across GPUs. Model parallel = split large model across devices (e.g., DDP, SMP)."
      },
      { mode: "exam", topic: "Model Development",
        q: "What is the purpose of SageMaker Experiments?",
        options: ["Only deploy models", "Track runs, parameters, metrics, and compare trials", "Store raw data only", "Manage IAM only"],
        correct: 1,
        explain: "Experiments = track training runs, hyperparameters, metrics; compare and reproduce."
      },
      { mode: "comparison", topic: "Model Development",
        q: "Which SageMaker capability provides a hosted Jupyter environment for ML development?",
        options: ["EC2 only", "SageMaker Studio", "Lambda", "ECS"],
        correct: 1,
        explain: "SageMaker Studio = integrated IDE; notebooks, experiments, pipelines, model registry."
      },
      // === DEPLOYMENT ===
      { mode: "comparison", topic: "Deployment",
        q: "For low-latency, real-time inference with auto scaling, which deployment option?",
        options: ["Batch Transform only", "SageMaker real-time inference endpoint", "S3 only", "Athena"],
        correct: 1,
        explain: "Real-time inference endpoint = single-digit ms latency; auto scaling; synchronous requests."
      },
      { mode: "comparison", topic: "Deployment",
        q: "For processing large datasets in batch without a persistent endpoint, which SageMaker option?",
        options: ["Real-time endpoint only", "SageMaker Batch Transform", "Lambda only", "API Gateway"],
        correct: 1,
        explain: "Batch Transform = run inference on large datasets; no endpoint; asynchronous, cost-effective."
      },
      { mode: "comparison", topic: "Deployment",
        q: "For serverless inference with automatic scaling to zero when idle, which option?",
        options: ["Real-time endpoint only", "SageMaker Serverless Inference", "EC2 only", "Fargate only"],
        correct: 1,
        explain: "SageMaker Serverless Inference = scale to zero; pay per inference; good for spiky workloads."
      },
      { mode: "exam", topic: "Deployment",
        q: "A/B testing different model versions can be done with which SageMaker feature?",
        options: ["Only separate endpoints", "Production variants with traffic splitting", "Batch Transform only", "S3 versioning"],
        correct: 1,
        explain: "Production variants = multiple models behind one endpoint; split traffic (e.g., 90/10) for A/B tests."
      },
      { mode: "exam", topic: "Deployment",
        q: "For CI/CD automation of ML model builds and deployments, which services are commonly used?",
        options: ["Manual only", "CodePipeline, CodeBuild, SageMaker Pipelines", "S3 only", "CloudWatch only"],
        correct: 1,
        explain: "CodePipeline + CodeBuild + SageMaker Pipelines = automate build, test, deploy ML workflows."
      },
      { mode: "comparison", topic: "Deployment",
        q: "Which service orchestrates multi-step ML workflows (data prep, train, evaluate, deploy)?",
        options: ["Lambda only", "SageMaker Pipelines", "Step Functions only", "S3 Events"],
        correct: 1,
        explain: "SageMaker Pipelines = orchestrate ML workflow; DAG of steps; integrate with CI/CD."
      },
      // === MONITORING & SECURITY ===
      { mode: "comparison", topic: "Monitoring",
        q: "Which SageMaker feature detects data drift and model quality degradation in production?",
        options: ["CloudWatch only", "SageMaker Model Monitor", "SageMaker Ground Truth", "S3 Events"],
        correct: 1,
        explain: "Model Monitor = data drift, model quality (bias, accuracy); schedule monitoring jobs."
      },
      { mode: "comparison", topic: "Monitoring",
        q: "For detecting bias and explaining model predictions, which SageMaker capability?",
        options: ["Model Monitor only", "SageMaker Clarify", "CloudWatch Logs only", "X-Ray"],
        correct: 1,
        explain: "SageMaker Clarify = bias metrics, feature attributions (SHAP), explainability reports."
      },
      { mode: "exam", topic: "Monitoring",
        q: "What does SageMaker Model Monitor track for data drift?",
        options: ["Only model accuracy", "Distribution of inputs vs baseline (training data)", "Cost only", "Latency only"],
        correct: 1,
        explain: "Model Monitor compares production input distribution to baseline; alerts on drift."
      },
      { mode: "exam", topic: "Security",
        q: "For securing SageMaker notebooks and training jobs, which practices apply?",
        options: ["Store credentials in code", "Use IAM roles, VPC, encryption at rest/transit", "No encryption", "Public S3 buckets"],
        correct: 1,
        explain: "IAM roles (no keys in code), VPC for network isolation, KMS for encryption, HTTPS for transit."
      },
      { mode: "exam", topic: "Security",
        q: "How can you restrict SageMaker training jobs to access only specific S3 buckets?",
        options: ["Hardcode paths in code", "IAM policies on the SageMaker execution role", "Security groups only", "NACLs only"],
        correct: 1,
        explain: "IAM execution role = least privilege; restrict s3:GetObject to needed buckets/prefixes."
      },
      // === MORE ===
      { mode: "comparison", topic: "Data Preparation",
        q: "For labeling training data at scale with human annotators, which AWS service?",
        options: ["SageMaker Data Wrangler", "SageMaker Ground Truth", "Mechanical Turk only", "Lambda"],
        correct: 1,
        explain: "SageMaker Ground Truth = built-in and custom workflows; human labeling; consolidation."
      },
      { mode: "comparison", topic: "Model Development",
        q: "For bringing your own Docker container to SageMaker training or inference, which feature?",
        options: ["Only built-in algorithms", "Bring Your Own Container (BYOC)", "Lambda only", "ECS only"],
        correct: 1,
        explain: "BYOC = use custom Docker images for training or inference; full control."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "EFS and FSx are suitable for SageMaker when you need:",
        options: ["Only S3", "Shared file system for multi-node training", "Object storage only", "Streaming only"],
        correct: 1,
        explain: "EFS/FSx = shared POSIX file system; useful for distributed training sharing data."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker Asynchronous Inference is best for:",
        options: ["Real-time sub-second latency", "Large payloads, long-running inference, queued requests", "Batch only", "Streaming only"],
        correct: 1,
        explain: "Asynchronous Inference = queue-based; large payloads, 60s+ inference; cost-effective."
      },
      { mode: "exam", topic: "Model Development",
        q: "What does SageMaker Managed Spot Training provide?",
        options: ["Only on-demand", "Use Spot instances for up to 90% savings; checkpointing required", "No savings", "Only for inference"],
        correct: 1,
        explain: "Managed Spot Training = use Spot for training; checkpoint to S3; resume if interrupted."
      },
      { mode: "comparison", topic: "Monitoring",
        q: "For centralized logging of SageMaker endpoints and training jobs, which service?",
        options: ["S3 only", "CloudWatch Logs", "DynamoDB", "Athena"],
        correct: 1,
        explain: "CloudWatch Logs = centralized logs for endpoints, training; integrate with alarms."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker multi-model endpoints (MME) allow:",
        options: ["One model per endpoint only", "Multiple models behind one endpoint; load dynamically", "Only Batch Transform", "No scaling"],
        correct: 1,
        explain: "MME = one endpoint, multiple models; load models on demand; reduce cost for many models."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker built-in algorithms are best when:",
        options: ["You need full custom code", "Standard algorithms (XGBoost, BlazingText, etc.) fit your use case", "Only custom containers", "No algorithms exist"],
        correct: 1,
        explain: "Built-in algorithms = pre-optimized; faster iteration; use when they fit. Otherwise BYOC or script mode."
      },
      { mode: "comparison", topic: "Data Preparation",
        q: "For querying data in S3 with SQL before feeding to SageMaker, which service?",
        options: ["Redshift only", "Amazon Athena", "RDS", "DynamoDB"],
        correct: 1,
        explain: "Athena = serverless SQL on S3; prepare/aggregate data for ML."
      },
      { mode: "exam", topic: "Monitoring",
        q: "SageMaker Model Monitor can send alerts to:",
        options: ["Only CloudWatch", "CloudWatch + SNS (email, Lambda, etc.)", "S3 only", "No alerts"],
        correct: 1,
        explain: "Model Monitor writes to CloudWatch; create alarms → SNS for notifications."
      },
      { mode: "comparison", topic: "Deployment",
        q: "For deploying a custom ML model packaged as a Docker image without SageMaker SDK, you can use:",
        options: ["SageMaker only", "ECS/EKS or Lambda (with container support)", "S3 only", "Athena"],
        correct: 1,
        explain: "ECS, EKS, Lambda (container) = alternative deployment; SageMaker preferred for integrated ML tooling."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "When using SageMaker Processing jobs for data preparation, what runs the processing script?",
        options: ["Lambda", "Managed SageMaker containers (or custom)", "API Gateway", "Step Functions only"],
        correct: 1,
        explain: "Processing jobs = run custom or built-in containers for data prep; managed, scalable."
      },
      { mode: "exam", topic: "Security",
        q: "SageMaker Studio supports which network isolation option?",
        options: ["Public only", "VPC mode for private subnet deployment", "No VPC", "NAT only"],
        correct: 1,
        explain: "Studio can run in VPC = no direct internet; access S3/data via VPC endpoints."
      },
      { mode: "comparison", topic: "Model Development",
        q: "For reinforcement learning on AWS, which service is typically used?",
        options: ["SageMaker Autopilot only", "SageMaker RL (with coach, Ray, etc.)", "Lambda", "Athena"],
        correct: 1,
        explain: "SageMaker RL = RL toolkits (e.g., Coach, Ray); train and deploy RL models."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker endpoint auto scaling is configured via:",
        options: ["Manual instance count only", "Application Auto Scaling (target tracking or custom)", "No scaling", "S3 only"],
        correct: 1,
        explain: "Application Auto Scaling = scale SageMaker endpoints by invocation count or custom metric."
      },
      { mode: "comparison", topic: "Data Preparation",
        q: "For migrating ML data from on-premises to S3, which AWS service helps?",
        options: ["Lambda only", "DataSync or Snowball", "Athena", "Redshift"],
        correct: 1,
        explain: "DataSync = network transfer; Snowball = offline for large datasets."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Debugger helps with:",
        options: ["Only deployment", "Profiling training (bottlenecks, utilization) and debugging (gradients, vanishing)", "Cost only", "Security only"],
        correct: 1,
        explain: "Debugger = profile training jobs; detect vanishing gradients, overfitting; optimize."
      },
      { mode: "exam", topic: "Monitoring",
        q: "What is the purpose of capturing inference data for Model Monitor?",
        options: ["Only for billing", "Establish baseline and compare production inputs/predictions to detect drift", "Backup only", "Compliance only"],
        correct: 1,
        explain: "Capture inference data → create baseline → compare production to detect data/model drift."
      },
      { mode: "comparison", topic: "Deployment",
        q: "For running inference on IoT edge devices, which SageMaker option?",
        options: ["Real-time endpoint only", "SageMaker Edge Manager (or Neo-compiled models)", "Batch Transform only", "Lambda only"],
        correct: 1,
        explain: "SageMaker Edge Manager = deploy to edge; Neo compiles models for edge hardware."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "RecordIO-Protobuf format in SageMaker is used for:",
        options: ["Only JSON", "Efficient streaming training with Pipe mode", "CSV only", "Database storage"],
        correct: 1,
        explain: "RecordIO-Protobuf = efficient for Pipe mode; streaming from S3 to training; faster I/O."
      },
      { mode: "exam", topic: "Security",
        q: "SageMaker supports encryption of which components?",
        options: ["Only notebooks", "Notebooks, training data (S3), model artifacts, endpoints (EBS)", "No encryption", "Only endpoints"],
        correct: 1,
        explain: "Encryption: S3 (SSE-S3, SSE-KMS), EBS for endpoints, notebooks; KMS for keys."
      },
      { mode: "comparison", topic: "Model Development",
        q: "For scalable, distributed training with TensorFlow or PyTorch, which SageMaker option?",
        options: ["Single instance only", "SageMaker distributed training (SDT) with supported frameworks", "Lambda", "Athena"],
        correct: 1,
        explain: "SageMaker supports distributed training for TF, PyTorch; data and model parallel."
      },
      { mode: "exam", topic: "Deployment",
        q: "Blue/green deployment for SageMaker endpoints is achieved by:",
        options: ["Redeploying in place", "New endpoint variant + traffic shift + old variant removal", "Batch only", "No automation"],
        correct: 1,
        explain: "Blue/green = deploy new variant, shift traffic, then remove old; minimal downtime."
      },
      // === TRIPLED: DATA PREP ===
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Processing can output to:",
        options: ["Only S3", "S3 or EFS; output path configurable", "Only DynamoDB", "Only Redshift"],
        correct: 1,
        explain: "Processing jobs write output to S3 or EFS; specify output path in job config."
      },
      { mode: "comparison", topic: "Data Preparation",
        q: "For incremental data load into a feature store, you would:",
        options: ["Full load only", "Append new events; use event time and deduplication", "Delete and reload", "No incremental"],
        correct: 1,
        explain: "Feature Store supports append; use event time and offline/online sync for incremental."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "Pipe mode in SageMaker training is used to:",
        options: ["Only batch", "Stream data from S3 to training without downloading fully", "Only real-time", "Only EBS"],
        correct: 1,
        explain: "Pipe mode = stream records from S3; lower latency, no full download; use RecordIO or similar."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Training compiles the model when using:",
        options: ["Only PyTorch", "Neo compiler for supported frameworks (deploy to edge or Inferentia)", "Only TensorFlow", "No compilation"],
        correct: 1,
        explain: "SageMaker Neo = compile model for edge or Inferentia; optimized inference."
      },
      { mode: "comparison", topic: "Model Development",
        q: "Script mode in SageMaker allows:",
        options: ["Only built-in algorithms", "Custom training script (PyTorch, TF, etc.) with SageMaker's container", "Only one framework", "No custom code"],
        correct: 1,
        explain: "Script mode = your training script; framework container handles distribution, checkpointing."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Training saves model artifacts to:",
        options: ["Only local disk", "S3 path specified in TrainingJob; output model, checkpoints", "DynamoDB", "EBS only"],
        correct: 1,
        explain: "Training job writes model artifacts to S3 output path; used for registry and deployment."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker Inference Recommender helps with:",
        options: ["Only cost", "Finding right instance type and config for your model", "Only latency", "Only batch"],
        correct: 1,
        explain: "Inference Recommender = load test and recommend instance type, count, and config."
      },
      { mode: "comparison", topic: "Deployment",
        q: "SageMaker multi-container endpoints allow:",
        options: ["One model only", "Multiple containers (e.g., pre- and post-processing) in one endpoint", "Only Batch Transform", "No containers"],
        correct: 1,
        explain: "Multi-container = chain containers (e.g., preprocessing + model + postprocessing) in one endpoint."
      },
      { mode: "exam", topic: "Monitoring",
        q: "SageMaker Model Monitor baseline is created from:",
        options: ["Production data only", "Training or sample data; compare production to this baseline", "Only real-time", "No baseline"],
        correct: 1,
        explain: "Baseline = statistics from training/sample data; production compared to baseline for drift."
      },
      { mode: "exam", topic: "Security",
        q: "SageMaker execution role is used for:",
        options: ["Only console access", "Training and inference jobs to access S3, ECR, etc.", "Only IAM users", "Only VPC"],
        correct: 1,
        explain: "Execution role = assumed by training/inference; grant least privilege to S3, ECR, etc."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Ground Truth supports:",
        options: ["Only image labeling", "Image, text, video, point cloud; custom workflows and active learning", "Only text", "Only video"],
        correct: 1,
        explain: "Ground Truth = multiple data types; custom workflows; active learning to reduce labeling cost."
      },
      { mode: "comparison", topic: "Model Development",
        q: "SageMaker Studio Labs provides:",
        options: ["Only on-prem", "Free tier ML environment (notebooks, no credit card)", "Only paid", "Only inference"],
        correct: 1,
        explain: "Studio Labs = free learning environment; limited compute; no credit card."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker endpoint scaling is based on:",
        options: ["Only manual", "Invocation count or custom CloudWatch metric via Application Auto Scaling", "Only time", "Only S3 events"],
        correct: 1,
        explain: "Application Auto Scaling = scale on InvocationsPerInstance or custom metric; min/max instances."
      },
      { mode: "exam", topic: "Monitoring",
        q: "SageMaker Clarify bias metrics include:",
        options: ["Only accuracy", "Pre-training and post-training bias (e.g., CI, DPL, CDDL)", "Only latency", "Only cost"],
        correct: 1,
        explain: "Clarify = pre-training (data) and post-training (predictions) bias metrics; configurable groups."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "Feature group in SageMaker Feature Store defines:",
        options: ["Only name", "Schema (feature names, types), offline/online store config", "Only online", "Only S3 path"],
        correct: 1,
        explain: "Feature group = name, feature definitions, record identifier, event time; offline + optional online."
      },
      { mode: "comparison", topic: "Model Development",
        q: "SageMaker JumpStart provides:",
        options: ["Only custom models", "Pre-built models, solutions, and notebooks to deploy or fine-tune", "Only inference", "Only data prep"],
        correct: 1,
        explain: "JumpStart = pre-built models (vision, NLP, etc.), solutions, notebooks; one-click deploy or fine-tune."
      },
      { mode: "exam", topic: "Deployment",
        q: "To reduce cold start on SageMaker Serverless Inference, you can:",
        options: ["Only increase memory", "Provision concurrency (keep instances warm)", "Only wait", "Only use real-time"],
        correct: 1,
        explain: "Provision concurrency = keep serverless instances warm; reduces cold start for first request."
      },
      { mode: "exam", topic: "Security",
        q: "SageMaker notebook instance in VPC can access S3 via:",
        options: ["Internet only", "VPC endpoint for S3 (gateway endpoint) so traffic stays private", "Only NAT", "Only public S3"],
        correct: 1,
        explain: "S3 gateway endpoint = private access from VPC; no internet for S3."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker distributed training data parallel uses:",
        options: ["Only one GPU", "Same model on each node; each node gets a shard of data", "Only model parallel", "No distribution"],
        correct: 1,
        explain: "Data parallel = replicate model; each node trains on different data shard; sync gradients."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Data Wrangler flows can export to:",
        options: ["Only S3", "SageMaker Pipelines, Python script, or run as Processing job", "Only Lambda", "Only Step Functions"],
        correct: 1,
        explain: "Export = Pipelines definition, Python, or run data prep as Processing job."
      },
      { mode: "comparison", topic: "Monitoring",
        q: "SageMaker Model Monitor can monitor:",
        options: ["Only accuracy", "Data quality, model quality, bias drift, feature attribution", "Only latency", "Only cost"],
        correct: 1,
        explain: "Model Monitor = data quality, model quality (e.g., accuracy), bias drift, explainability."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker Batch Transform output can be:",
        options: ["Only S3", "S3 with optional inference attributes (e.g., probability)", "DynamoDB only", "Only real-time"],
        correct: 1,
        explain: "Batch Transform writes to S3; optional JoinSource to merge with input; inference attributes configurable."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker automatic model tuning (hyperparameter tuning) uses:",
        options: ["Only grid search", "Bayesian or random search over hyperparameter ranges", "Only manual", "Only one job"],
        correct: 1,
        explain: "Hyperparameter tuning = multiple training jobs; Bayesian (default) or random search; max jobs, max parallel."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "For very large training datasets, best practice is:",
        options: ["Load all into memory", "Use Pipe mode or Fast File mode; shard by object or record", "Only single file", "Only CSV"],
        correct: 1,
        explain: "Shard data across nodes; Pipe or Fast File for efficient streaming from S3."
      },
      { mode: "comparison", topic: "Security",
        q: "SageMaker model artifacts in S3 should be:",
        options: ["Public", "Encrypted (SSE-S3 or SSE-KMS) and access via IAM only", "Unencrypted", "Only in EBS"],
        correct: 1,
        explain: "Encrypt model bucket; restrict access with IAM; no public access."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Experiments automatically tracks:",
        options: ["Only cost", "Parameters, metrics, artifacts when using SageMaker SDK", "Only logs", "Only model ID"],
        correct: 1,
        explain: "Experiments = log parameters, metrics, artifacts; compare runs; SDK integrates with training."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker Asynchronous Inference uses:",
        options: ["Only sync API", "S3 for input/output; queue; optional SNS notification", "Only Lambda", "Only Batch Transform"],
        correct: 1,
        explain: "Async = upload input to S3; job runs; output to S3; optional SNS when done."
      },
      { mode: "exam", topic: "Monitoring",
        q: "To trigger retraining when drift is detected, you can:",
        options: ["Only manual", "EventBridge or Lambda on Model Monitor alarm; trigger pipeline", "Only Cron", "No automation"],
        correct: 1,
        explain: "Model Monitor → CloudWatch alarm → EventBridge/Lambda → start retrain pipeline."
      },
      { mode: "comparison", topic: "Data Preparation",
        q: "SageMaker Feature Store offline store is used for:",
        options: ["Only real-time inference", "Training; bulk export for model training", "Only online", "Only DynamoDB"],
        correct: 1,
        explain: "Offline store = S3; historical features for training. Online = low-latency for inference."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Debugger can detect:",
        options: ["Only accuracy", "Vanishing gradients, overfitting, poor initialization", "Only latency", "Only cost"],
        correct: 1,
        explain: "Debugger = rules and profiling; vanishing gradients, overfitting, etc.; optional auto-stop."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker endpoint variant can have:",
        options: ["Only one instance", "Instance type, count, and model; traffic split across variants", "Only model", "No scaling"],
        correct: 1,
        explain: "Variant = model + instance type + instance count; multiple variants with traffic split (A/B)."
      },
      { mode: "exam", topic: "Security",
        q: "To allow SageMaker to pull a private Docker image from ECR:",
        options: ["Use public image only", "Execution role needs ECR read; image in same account or cross-account policy", "No ECR", "Only public ECR"],
        correct: 1,
        explain: "Execution role = ecr:GetDownloadUrlForLayer, GetAuthorizationToken; image URI in same or other account."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "Glue Data Catalog can be used as feature store:",
        options: ["No", "Not directly; SageMaker Feature Store is separate; Glue for ETL catalog", "Yes, same service", "Only for inference"],
        correct: 1,
        explain: "Feature Store = SageMaker native. Glue = data catalog for ETL/Athena; different use case."
      },
      { mode: "comparison", topic: "Model Development",
        q: "SageMaker Training job lifecycle includes:",
        options: ["Only run", "Provision, download data/code, run, upload artifacts, terminate", "Only upload", "Only terminate"],
        correct: 1,
        explain: "Training = launch instance(s), pull image, get data, train, save artifacts to S3, terminate."
      },
      { mode: "exam", topic: "Monitoring",
        q: "SageMaker Model Monitor schedule can be:",
        options: ["Only on-demand", "Periodic (e.g., hourly) or per-batch; compare to baseline", "Only once", "Only at deploy"],
        correct: 1,
        explain: "Monitoring schedule = periodic or per Batch Transform; run comparison, emit metrics."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker real-time endpoint minimum instance count of 0 is:",
        options: ["Always allowed", "Not for real-time; use Serverless Inference for scale-to-zero", "Only for Batch", "Only for async"],
        correct: 1,
        explain: "Real-time = min 1 or more. Serverless = scale to zero when idle."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker managed Spot Training saves money by:",
        options: ["Using smaller instances only", "Using Spot instances; checkpoint to S3 to resume if interrupted", "No savings", "Only for inference"],
        correct: 1,
        explain: "Spot = up to 90% savings; must checkpoint; job resumes from last checkpoint if interrupted."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Data Wrangler supports connectors to:",
        options: ["Only S3", "S3, Athena, Redshift, Snowflake, and more", "Only Redshift", "Only RDS"],
        correct: 1,
        explain: "Data Wrangler = connect to S3, Athena, Redshift, Snowflake, etc.; import and transform."
      },
      { mode: "comparison", topic: "Deployment",
        q: "SageMaker vs Lambda for inference:",
        options: ["Same thing", "SageMaker = ML-optimized, larger payloads, GPU; Lambda = small, event-driven", "Only Lambda", "Only SageMaker"],
        correct: 1,
        explain: "SageMaker = ML endpoints, GPUs, large models. Lambda = small, serverless; can call SageMaker."
      },
      { mode: "exam", topic: "Security",
        q: "SageMaker notebook can use a custom VPC to:",
        options: ["Only speed", "Access resources in VPC (RDS, Redshift) without public internet", "Only cost", "Only logging"],
        correct: 1,
        explain: "Notebook in VPC = access RDS, Redshift, etc. via private subnet; VPC endpoints for S3/SageMaker."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Pipelines steps can include:",
        options: ["Only training", "Processing, training, tuning, conditional, register model, create endpoint", "Only deploy", "Only transform"],
        correct: 1,
        explain: "Pipelines = DAG of steps: process, train, condition, register, deploy; parameters and caching."
      },
      { mode: "exam", topic: "Monitoring",
        q: "SageMaker Model Monitor emits metrics to:",
        options: ["Only S3", "CloudWatch (custom namespace); create alarms", "Only logs", "Only X-Ray"],
        correct: 1,
        explain: "Model Monitor writes metrics to CloudWatch; SageMaker namespace; alarm on drift or errors."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "For labeling with SageMaker Ground Truth, you can use:",
        options: ["Only Amazon workforce", "Amazon, vendor, or custom workforce; and active learning", "Only custom", "No workforce"],
        correct: 1,
        explain: "Ground Truth = public (MTurk), vendor, or private workforce; active learning to reduce labels."
      },
      { mode: "comparison", topic: "Model Development",
        q: "SageMaker Studio and Studio Classic differ in:",
        options: ["No difference", "Studio = new web-based; Classic = legacy Jupyter-based", "Only name", "Only region"],
        correct: 1,
        explain: "Studio = new unified IDE. Studio Classic = original Jupyter-based; both support notebooks, pipelines."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker endpoint update (in-place) can:",
        options: ["Only replace model", "Update variant (model, instance type, count) with optional rolling update", "Only add variant", "No update"],
        correct: 1,
        explain: "UpdateEndpointConfig + UpdateEndpoint = new config; rolling update to reduce downtime."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Training job uses which container image?",
        options: ["Only custom", "Pre-built framework container (TF, PyTorch, etc.) or bring your own", "Only pre-built", "Only ECR public"],
        correct: 1,
        explain: "Training = specify pre-built image (by framework/version) or custom ECR image."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Feature Store online store typically uses:",
        options: ["S3 only", "DynamoDB (or similar) for low-latency feature lookup", "Only Redshift", "Only RDS"],
        correct: 1,
        explain: "Online store = DynamoDB (default) for millisecond feature lookup at inference."
      },
      { mode: "exam", topic: "Monitoring",
        q: "SageMaker Clarify explainability provides:",
        options: ["Only accuracy", "Feature attribution (SHAP) per prediction or global", "Only bias", "Only drift"],
        correct: 1,
        explain: "Clarify = SHAP values; which features drove the prediction; configurable."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker Serverless Inference is suitable when:",
        options: ["Always high traffic", "Intermittent or unpredictable traffic; pay per inference", "Only batch", "Only real-time 24/7"],
        correct: 1,
        explain: "Serverless = scale to zero; pay per request; good for spiky or low traffic."
      },
      { mode: "exam", topic: "Security",
        q: "SageMaker network isolation can be achieved with:",
        options: ["Public subnet only", "VPC with private subnets; no direct internet; VPC endpoints", "Only security groups", "Only NACL"],
        correct: 1,
        explain: "Place SageMaker in VPC private subnet; use VPC endpoints for S3, SageMaker, ECR."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker local mode is used for:",
        options: ["Production only", "Testing training or inference scripts locally (Docker)", "Only inference", "Only data prep"],
        correct: 1,
        explain: "Local mode = run training or inference in local Docker; faster iteration; not for production."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Processing supports:",
        options: ["Only Spark", "Built-in Spark, or custom container (e.g., scikit-learn)", "Only custom", "Only PyTorch"],
        correct: 1,
        explain: "Processing = Spark (built-in) or bring your own container for any preprocessing."
      },
      { mode: "comparison", topic: "Deployment",
        q: "SageMaker inference with GPU is used when:",
        options: ["Always", "Model requires GPU for latency or throughput (e.g., large vision)", "Only training", "Only batch"],
        correct: 1,
        explain: "GPU instances = for compute-heavy inference (vision, large NLP); higher cost, higher throughput."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker model registry approval workflow:",
        options: ["No approval", "Register model; optional approval status (e.g., Approved) for deployment", "Only manual deploy", "Only automatic"],
        correct: 1,
        explain: "Model registry = version models; set status (e.g., Approved); CI/CD can deploy only approved."
      },
      { mode: "exam", topic: "Monitoring",
        q: "To capture both input and output for Model Monitor, you:",
        options: ["Only log", "Enable endpoint data capture (percentage of traffic); write to S3", "Only CloudWatch", "Only X-Ray"],
        correct: 1,
        explain: "Data capture = sample request/response to S3; used for baseline and ongoing comparison."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Data Wrangler transformations are:",
        options: ["Only manual code", "Visual or code; filter, encode, scale, etc.", "Only filter", "Only export"],
        correct: 1,
        explain: "Data Wrangler = visual transforms (filter, encode, scale); or edit generated code."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker multi-model endpoint (MME) loads models:",
        options: ["All at once only", "On demand from S3; unload when idle to save memory", "Only one model", "Only at startup"],
        correct: 1,
        explain: "MME = load model on first request; unload when idle; share capacity across many models."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker distributed model parallel (e.g., SMP) is for:",
        options: ["Small models only", "Models that don't fit on one device; partition across GPUs", "Only data parallel", "Only CPU"],
        correct: 1,
        explain: "Model parallel = split model across devices; for very large models (e.g., billions of parameters)."
      },
      { mode: "exam", topic: "Security",
        q: "SageMaker and KMS:",
        options: ["No KMS", "Use KMS to encrypt notebooks, artifacts, and optionally S3", "Only S3", "Only notebooks"],
        correct: 1,
        explain: "SageMaker uses KMS for notebook volumes, optional for S3; customer-managed key supported."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Ground Truth output format includes:",
        options: ["Only JSON", "Manifest (JSON lines) with annotations; optional auto-labeling", "Only CSV", "Only Parquet"],
        correct: 1,
        explain: "Ground Truth outputs manifest file with image/text ref and annotation; use for training."
      },
      { mode: "comparison", topic: "Model Development",
        q: "SageMaker built-in XGBoost supports:",
        options: ["Only CPU", "CPU or GPU; single-node or distributed", "Only single node", "Only custom container"],
        correct: 1,
        explain: "Built-in XGBoost = CPU/GPU; single or distributed; no container to manage."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker endpoint creation requires:",
        options: ["Only model name", "Model (or multi-model config), instance type/count, optional variant name", "Only instance", "Only S3"],
        correct: 1,
        explain: "CreateEndpointConfig = model(s), instance type, count. CreateEndpoint = config name."
      },
      { mode: "exam", topic: "Monitoring",
        q: "SageMaker Model Monitor data quality monitor compares:",
        options: ["Only accuracy", "Production input distribution to baseline (schema, stats)", "Only latency", "Only cost"],
        correct: 1,
        explain: "Data quality = baseline schema and statistics; production compared; alert on drift."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Training job instance type is chosen based on:",
        options: ["Only cost", "Model size, framework, GPU need, and budget", "Only GPU", "Only CPU"],
        correct: 1,
        explain: "CPU for small models; GPU (g4dn, p3, etc.) for large or GPU-optimized; multi-GPU for distributed."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Feature Store record identifier and event time:",
        options: ["Optional", "Required; record identifier is primary key; event time for point-in-time join", "Only event time", "Only identifier"],
        correct: 1,
        explain: "Record identifier = unique per entity. Event time = for time-based feature join in training."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker Batch Transform supports:",
        options: ["Only one file", "Multiple input files; split by line or use JoinSource", "Only S3", "Only CSV"],
        correct: 1,
        explain: "Batch Transform = one or many files; split type (Line, RecordIO); optional JoinSource."
      },
      { mode: "exam", topic: "Security",
        q: "Cross-account SageMaker training:",
        options: ["Not supported", "Possible with cross-account S3/ECR access and execution role", "Only same account", "Only inference"],
        correct: 1,
        explain: "Training in account A can read S3/ECR from B with bucket/role policies; execution role in A."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Training job max runtime is:",
        options: ["No limit", "Configurable (e.g., 86400 seconds); job stopped if exceeded", "Only 1 hour", "Only 24 hours"],
        correct: 1,
        explain: "MaxRuntimeInSeconds = stop training after this time; avoid runaway jobs."
      },
      { mode: "exam", topic: "Monitoring",
        q: "SageMaker Model Monitor model quality monitor requires:",
        options: ["Only input capture", "Ground truth labels (e.g., from batch job or human) to compute accuracy", "No labels", "Only drift"],
        correct: 1,
        explain: "Model quality = compare predictions to ground truth; need labels (e.g., from batch or feedback)."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Data Wrangler destination can be:",
        options: ["Only S3", "S3, or direct to SageMaker Feature Store", "Only Feature Store", "Only Athena"],
        correct: 1,
        explain: "Data Wrangler can export to S3 or write to Feature Store."
      },
      { mode: "comparison", topic: "Deployment",
        q: "SageMaker inference with Inferentia (Inf1) is for:",
        options: ["Only training", "Cost-effective inference for supported models (e.g., compiled)", "Only GPU", "Only CPU"],
        correct: 1,
        explain: "Inferentia = custom chip for inference; compile model with Neo; lower cost for compatible workloads."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Pipelines parameterization allows:",
        options: ["No parameters", "Pass parameters at run time (e.g., data path, instance type)", "Only at create", "Only in steps"],
        correct: 1,
        explain: "Pipeline parameters = pass at start run; override defaults; reuse same pipeline with different inputs."
      },
      { mode: "exam", topic: "Security",
        q: "SageMaker notebook instance root access:",
        options: ["Always root", "Optional; can disable root access for shared environments", "Only root", "No option"],
        correct: 1,
        explain: "Lifecycle config can restrict root; use for shared or compliant environments."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Ground Truth active learning:",
        options: ["Not available", "Uses model to select which samples to label next; reduce cost", "Only manual", "Only automatic labeling"],
        correct: 1,
        explain: "Active learning = model suggests uncertain samples for human label; fewer labels needed."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker endpoint deletion:",
        options: ["Keeps instances", "Deletes endpoint and endpoint config; instances terminated", "Only config", "Only model"],
        correct: 1,
        explain: "DeleteEndpoint = stop billing; config and model artifacts in S3 remain unless deleted."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Training job uses EBS for:",
        options: ["Only model output", "Instance storage (optional size); data cache, scratch", "Only S3", "No EBS"],
        correct: 1,
        explain: "Training instance has root volume; optional additional EBS for large local data/cache."
      },
      { mode: "exam", topic: "Monitoring",
        q: "SageMaker Model Monitor and Clarify can run:",
        options: ["Only real-time", "On schedule (batch) or per Batch Transform; not necessarily real-time", "Only once", "Only at deploy"],
        correct: 1,
        explain: "Monitoring can be scheduled (e.g., daily) or attached to Batch Transform; real-time optional."
      },
      { mode: "exam", topic: "Data Preparation",
        q: "SageMaker Feature Store get_record is used for:",
        options: ["Only batch", "Online store; get latest feature vector for an entity at inference", "Only offline", "Only training"],
        correct: 1,
        explain: "get_record = low-latency lookup from online store; one entity's features for real-time inference."
      },
      { mode: "exam", topic: "Deployment",
        q: "SageMaker real-time endpoint invocations are:",
        options: ["Async only", "Synchronous; client sends request, waits for response", "Only batch", "Only S3"],
        correct: 1,
        explain: "InvokeEndpoint = sync; send body, get response; low latency."
      },
      { mode: "exam", topic: "Model Development",
        q: "SageMaker Training job failure:",
        options: ["Always retries", "Configurable retry; logs and partial artifacts in S3", "No logs", "No artifacts"],
        correct: 1,
        explain: "Failed job = check CloudWatch logs, S3 output; RetryStrategy configurable for transient failures."
      },
    ];
