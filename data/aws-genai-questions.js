window.QUESTION_BANK_AWS_GENAI = [
      // === BEDROCK BASICS ===
      { mode: "comparison", topic: "Bedrock",
        q: "Amazon Bedrock provides access to foundation models (FMs) through which model delivery option?",
        options: ["Only bring-your-own model", "API access to FMs from Amazon and third parties (no infrastructure to manage)", "Only Amazon Titan", "Only open-source models"],
        correct: 1,
        explain: "Bedrock = fully managed; access FMs from Amazon and third-party providers via API; no servers to manage."
      },
      { mode: "exam", topic: "Bedrock",
        q: "To use a foundation model in Bedrock for the first time, you must:",
        options: ["Deploy the model to EC2", "Enable model access in the Bedrock console (Model Access in the left menu)", "Use only default models", "Request a custom fine-tune"],
        correct: 1,
        explain: "Model access must be enabled per model (and per region) before you can invoke it."
      },
      { mode: "exam", topic: "Bedrock",
        q: "Bedrock Inference supports which invocation patterns?",
        options: ["Synchronous only", "Synchronous (InvokeModel) and asynchronous (InvokeModelWithResponseStream)", "Batch only", "Only streaming"],
        correct: 1,
        explain: "InvokeModel = sync; InvokeModelWithResponseStream = stream tokens; async for long-running inference."
      },
      { mode: "comparison", topic: "Bedrock",
        q: "Amazon Bedrock Serverless Inference is best for:",
        options: ["Only high-throughput batch", "Variable or unpredictable traffic; pay per request", "Only reserved capacity", "Only real-time always-on"],
        correct: 1,
        explain: "Serverless = no capacity to manage; pay per request; good for variable traffic."
      },
      { mode: "exam", topic: "Bedrock",
        q: "Provisioned Throughput in Bedrock is used when you need:",
        options: ["Only serverless", "Predictable capacity and guaranteed throughput (dedicated model units)", "Only on-demand", "Only batch"],
        correct: 1,
        explain: "Provisioned Throughput = reserve model units for predictable performance; commit to capacity."
      },
      // === RAG & KNOWLEDGE BASES ===
      { mode: "comparison", topic: "RAG",
        q: "A RAG (Retrieval-Augmented Generation) solution on AWS typically uses Bedrock with:",
        options: ["Only the base model", "Bedrock Knowledge Bases (retrieve from your data, then generate)", "Only Lambda", "Only S3 without retrieval"],
        correct: 1,
        explain: "Knowledge Bases = ingest your data (S3, etc.), create embeddings, retrieve relevant chunks for context in prompts."
      },
      { mode: "exam", topic: "RAG",
        q: "Bedrock Knowledge Bases can use which vector store?",
        options: ["Only OpenSearch", "Amazon OpenSearch Serverless, Pinecone, or Redis Enterprise Cloud", "Only DynamoDB", "Only RDS"],
        correct: 1,
        explain: "Knowledge Bases support OpenSearch Serverless, Pinecone, Redis Enterprise as vector stores."
      },
      { mode: "exam", topic: "RAG",
        q: "When building RAG, embedding models in Bedrock are used to:",
        options: ["Only generate text", "Convert text to vector embeddings for retrieval", "Only summarize", "Only translate"],
        correct: 1,
        explain: "Embedding models (e.g., Titan Embeddings) convert text to vectors for similarity search in the vector store."
      },
      { mode: "exam", topic: "RAG",
        q: "Chunking strategy in RAG affects:",
        options: ["Only cost", "Retrieval quality and relevance (size, overlap, semantics)", "Only latency", "Only model choice"],
        correct: 1,
        explain: "Chunk size and overlap affect what gets retrieved; too large or too small can hurt answer quality."
      },
      // === AGENTS ===
      { mode: "comparison", topic: "Agents",
        q: "Bedrock Agents are used to:",
        options: ["Only run batch jobs", "Orchestrate multi-step tasks with tools and knowledge bases", "Only invoke a single model", "Only store embeddings"],
        correct: 1,
        explain: "Agents = orchestrate FMs with action groups (APIs, Lambda) and optional knowledge bases; multi-step reasoning."
      },
      { mode: "exam", topic: "Agents",
        q: "An action group in a Bedrock Agent typically:",
        options: ["Only returns static text", "Defines APIs or Lambda functions the agent can call to perform actions", "Only retrieves from Knowledge Base", "Only streams tokens"],
        correct: 1,
        explain: "Action groups = define tools (OpenAPI schema + Lambda or API) the agent can invoke."
      },
      { mode: "exam", topic: "Agents",
        q: "To keep agent behavior consistent and controllable, you should:",
        options: ["Only use the default system prompt", "Configure instructions (system prompt) and guardrails", "Only use one action group", "Only use streaming"],
        correct: 1,
        explain: "Instructions and guardrails shape agent behavior; use them for consistency and safety."
      },
      // === GUARDRAILS & SAFETY ===
      { mode: "comparison", topic: "Guardrails",
        q: "Bedrock Guardrails help with:",
        options: ["Only cost control", "Content filtering and safety (deny harmful or off-topic content)", "Only scaling", "Only logging"],
        correct: 1,
        explain: "Guardrails = apply content filters (hate, violence, PII, etc.) and topic policies on input/output."
      },
      { mode: "exam", topic: "Guardrails",
        q: "Guardrails can be applied at:",
        options: ["Model level only", "Input (prompt) and/or output (response) stages", "Only output", "Only in Knowledge Base"],
        correct: 1,
        explain: "Guardrails evaluate and block/filter at input and/or output; configurable per stage."
      },
      { mode: "exam", topic: "Security",
        q: "To run Bedrock inference inside your VPC without internet, you would use:",
        options: ["Only public Bedrock endpoints", "VPC endpoints for Bedrock (and optionally PrivateLink)", "Only NAT Gateway", "Only VPN"],
        correct: 1,
        explain: "Use VPC endpoints (interface endpoints) for Bedrock so traffic stays on the AWS network; optional PrivateLink for private access."
      },
      { mode: "exam", topic: "Security",
        q: "Bedrock supports encryption of model data:",
        options: ["Only in transit", "At rest (AWS managed or customer-managed keys in KMS) and in transit", "Only at rest", "No encryption"],
        correct: 1,
        explain: "Encryption at rest with KMS (default or CMK); TLS in transit."
      },
      // === DEPLOYMENT & PRODUCTION ===
      { mode: "exam", topic: "Deployment",
        q: "For a production GenAI app that must scale with traffic, a common pattern is:",
        options: ["Single EC2 instance only", "API Gateway + Lambda (or container) invoking Bedrock", "Only SageMaker real-time", "Only batch"],
        correct: 1,
        explain: "API Gateway + Lambda/container calling Bedrock = serverless, scalable; add caching and throttling as needed."
      },
      { mode: "exam", topic: "Deployment",
        q: "Amazon SageMaker JumpStart can be used for GenAI to:",
        options: ["Only Bedrock", "Deploy and fine-tune open-source FMs (e.g., Llama) on SageMaker", "Only Knowledge Bases", "Only agents"],
        correct: 1,
        explain: "JumpStart = deploy pre-built models (including LLMs) and fine-tune; alternative to Bedrock for bring-your-own."
      },
      { mode: "exam", topic: "Cost",
        q: "To optimize cost when using Bedrock with variable traffic, you should consider:",
        options: ["Only Provisioned Throughput", "On-Demand or Serverless for variable load; Provisioned Throughput for steady high load", "Only On-Demand", "Only custom models"],
        correct: 1,
        explain: "On-Demand/Serverless = pay per use; Provisioned = commit for predictable, high throughput; match to traffic pattern."
      },
      { mode: "exam", topic: "Cost",
        q: "Bedrock pricing is typically based on:",
        options: ["Only API calls", "Input and output tokens (and optionally model units for Provisioned Throughput)", "Only storage", "Only requests"],
        correct: 1,
        explain: "Pay per input token and output token (varies by model); Provisioned Throughput adds model unit pricing."
      },
      // === MORE EXAM-STYLE ===
      { mode: "exam", topic: "Bedrock",
        q: "Which Bedrock feature allows you to fine-tune a model on your own data?",
        options: ["Only base model invocation", "Bedrock Custom Model (fine-tune supported models with your dataset)", "Only Knowledge Base", "Only Guardrails"],
        correct: 1,
        explain: "Custom Model = fine-tune supported FMs (e.g., Cohere, Amazon Titan) with your data in S3."
      },
      { mode: "exam", topic: "RAG",
        q: "In RAG, the purpose of the retrieval step is to:",
        options: ["Replace the model", "Fetch relevant context from your data to add to the prompt", "Only cache responses", "Only validate output"],
        correct: 1,
        explain: "Retrieve relevant documents/chunks; concatenate with user prompt so the FM has context to answer accurately."
      },
      { mode: "exam", topic: "Agents",
        q: "When a Bedrock Agent uses a Knowledge Base, it:",
        options: ["Only calls action groups", "Can retrieve from the Knowledge Base and optionally call action groups", "Only streams", "Only uses one model"],
        correct: 1,
        explain: "Agent can use both Knowledge Base (retrieval) and action groups (tools); configured in the agent."
      },
      { mode: "exam", topic: "Guardrails",
        q: "A guardrail topic policy is used to:",
        options: ["Only filter PII", "Restrict conversation to approved topics or deny prohibited topics", "Only filter violence", "Only log requests"],
        correct: 1,
        explain: "Topic policies = allow list or deny list of topics; keep the model on-topic."
      },
      { mode: "exam", topic: "Security",
        q: "To allow only specific IAM principals to call Bedrock, you should:",
        options: ["Only use VPC", "Use IAM policies (and optionally resource policies) on the Bedrock resources", "Only use Guardrails", "Only use encryption"],
        correct: 1,
        explain: "IAM policies control who can invoke models; use least privilege; resource policies for cross-account if needed."
      },
      { mode: "exam", topic: "Deployment",
        q: "For low-latency inference at high scale, a suitable option is:",
        options: ["Only Lambda with no concurrency", "Provisioned Throughput (dedicated capacity) or SageMaker real-time endpoint", "Only on-demand with no cache", "Only batch"],
        correct: 1,
        explain: "Provisioned Throughput = dedicated capacity, predictable latency; SageMaker = custom models with dedicated instances."
      },
      { mode: "exam", topic: "Monitoring",
        q: "To trace and debug Bedrock invocations in production, you can use:",
        options: ["Only CloudWatch Logs", "AWS X-Ray (and CloudWatch) for tracing and metrics", "Only Guardrails", "Only Knowledge Base logs"],
        correct: 1,
        explain: "X-Ray = trace requests across services; CloudWatch = logs and metrics; use both for observability."
      },
      { mode: "exam", topic: "Bedrock",
        q: "InvokeModelWithResponseStream returns:",
        options: ["Only a single block of text", "A stream of response chunks (e.g., for real-time UX)", "Only metadata", "Only embeddings"],
        correct: 1,
        explain: "Streaming API = receive chunks as the model generates; better UX for chat and long responses."
      },
      { mode: "exam", topic: "RAG",
        q: "Hybrid search in a RAG context typically combines:",
        options: ["Only two embedding models", "Keyword (e.g., BM25) and semantic (vector) search", "Only vector search", "Only keyword search"],
        correct: 1,
        explain: "Hybrid = keyword + vector; improves retrieval when exact terms or semantics matter."
      },
      { mode: "exam", topic: "Agents",
        q: "Agent memory (session state) in Bedrock Agents is used to:",
        options: ["Only store embeddings", "Persist conversation context across turns", "Only cache model output", "Only log actions"],
        correct: 1,
        explain: "Session state = store conversation history and context so the agent has memory across turns."
      },
      { mode: "exam", topic: "Guardrails",
        q: "PII filter in Guardrails can:",
        options: ["Only log PII", "Detect and redact or block PII in input/output", "Only block all text", "Only allow PII"],
        correct: 1,
        explain: "PII filters = detect and redact or block (e.g., SSN, names) to meet compliance."
      },
      { mode: "exam", topic: "Security",
        q: "Cross-account access to Bedrock can be granted via:",
        options: ["Only same-account IAM", "Resource-based policies (e.g., on Bedrock) and IAM in the other account", "Only VPC peering", "Only Guardrails"],
        correct: 1,
        explain: "Use resource policy on the Bedrock resource to allow another account; other account needs IAM to call."
      },
      { mode: "exam", topic: "Cost",
        q: "Caching Bedrock model responses is useful when:",
        options: ["Traffic is always unique", "Similar prompts repeat (reduce cost and latency)", "Only for batch", "Only for streaming"],
        correct: 1,
        explain: "Cache repeated or similar prompts (e.g., prompt cache in Bedrock or application-level cache) to save tokens and latency."
      },
      { mode: "exam", topic: "Deployment",
        q: "AWS Lambda is a good fit for Bedrock invocation when:",
        options: ["Only long-running batch", "Event-driven, variable load, and invocation fits within Lambda timeout", "Only real-time 24/7", "Only Provisioned Throughput"],
        correct: 1,
        explain: "Lambda = event-driven, scales automatically; ensure inference fits within 15 min timeout and memory limits."
      },
      { mode: "exam", topic: "Bedrock",
        q: "Model ID in Bedrock (e.g., anthropic.claude-3-sonnet) identifies:",
        options: ["Only the region", "The specific foundation model and variant to invoke", "Only the account", "Only the endpoint"],
        correct: 1,
        explain: "Model ID = provider.model-name (e.g., amazon.titan-text-express); required for InvokeModel."
      },
      { mode: "exam", topic: "RAG",
        q: "Metadata filtering in a Knowledge Base query allows you to:",
        options: ["Only filter by date", "Restrict retrieval to documents matching metadata (e.g., department, locale)", "Only filter by size", "Only filter by model"],
        correct: 1,
        explain: "Metadata filters = narrow retrieval to chunks that match key-value filters; improves relevance."
      },
      { mode: "exam", topic: "Agents",
        q: "Prepared prompts (prompt templates) in Bedrock Agents help with:",
        options: ["Only logging", "Consistent, reusable prompt structure and variables", "Only streaming", "Only action groups"],
        correct: 1,
        explain: "Prepared prompts = templates with placeholders; standardize and reuse prompt structure."
      },
      { mode: "exam", topic: "Guardrails",
        q: "Word filters in Guardrails can:",
        options: ["Only allow all words", "Block or replace specific words/phrases (e.g., profanity, competitors)", "Only log words", "Only for PII"],
        correct: 1,
        explain: "Word filters = block list or replace list for specific terms; configurable."
      },
      { mode: "exam", topic: "Monitoring",
        q: "CloudWatch metrics for Bedrock can include:",
        options: ["Only cost", "Invocation count, latency, errors (by model, account)", "Only tokens", "Only streaming"],
        correct: 1,
        explain: "Bedrock emits metrics (Invocations, InvocationLatency, etc.); use for monitoring and alarms."
      },
      { mode: "exam", topic: "Bedrock",
        q: "Bedrock supports which type of models for text generation?",
        options: ["Only Amazon models", "Amazon (Titan, etc.) and third-party (Anthropic, Cohere, Meta, etc.)", "Only open-source", "Only custom"],
        correct: 1,
        explain: "Bedrock = multi-provider; Amazon Titan, Anthropic Claude, Cohere, Meta Llama, etc.; enable per model."
      },
      { mode: "exam", topic: "RAG",
        q: "When ingestion runs for a Bedrock Knowledge Base, it:",
        options: ["Only deletes data", "Syncs data source (e.g., S3), chunks, generates embeddings, writes to vector store", "Only invokes the model", "Only updates Guardrails"],
        correct: 1,
        explain: "Ingestion = read from data source, chunk, embed, store in vector store; run on schedule or on-demand."
      },
      { mode: "exam", topic: "Agents",
        q: "Agent validation in Bedrock helps:",
        options: ["Only with cost", "Test the agent (e.g., test cases) before deployment", "Only with streaming", "Only with action groups"],
        correct: 1,
        explain: "Validation = run test cases against the agent; ensure it behaves as expected before release."
      },
      { mode: "exam", topic: "Security",
        q: "To meet compliance, you should for Bedrock:",
        options: ["Only use default settings", "Use encryption (KMS), VPC, IAM least privilege, and Guardrails as appropriate", "Only use Guardrails", "Only use public endpoints"],
        correct: 1,
        explain: "Encryption, network isolation (VPC), least privilege IAM, and content controls (Guardrails) support compliance."
      },
      { mode: "exam", topic: "Deployment",
        q: "Blue/green or canary deployment for a GenAI API is useful to:",
        options: ["Only reduce cost", "Roll out model or prompt changes with reduced risk", "Only increase latency", "Only for batch"],
        correct: 1,
        explain: "Blue/green or canary = release new version to a subset; validate before full rollout."
      },
      { mode: "exam", topic: "Cost",
        q: "Choosing a smaller or more efficient model in Bedrock can:",
        options: ["Only increase latency", "Reduce cost and often latency for suitable tasks", "Only reduce accuracy", "Only increase tokens"],
        correct: 1,
        explain: "Smaller models (e.g., Titan Text Express vs. Claude) can be cheaper and faster for simpler tasks."
      },
      { mode: "exam", topic: "Bedrock",
        q: "Converse API in Bedrock provides:",
        options: ["Only single-turn invoke", "Unified chat interface (messages, tool use, streaming) for supported models", "Only embeddings", "Only batch"],
        correct: 1,
        explain: "Converse API = multi-turn chat; send message history, optional tool config; simpler than raw InvokeModel for chat."
      },
      { mode: "exam", topic: "RAG",
        q: "Re-ranking retrieved chunks before adding to the prompt can:",
        options: ["Only increase cost", "Improve relevance by scoring and selecting the best chunks", "Only decrease latency", "Only reduce tokens"],
        correct: 1,
        explain: "Re-ranking = score retrieved chunks (e.g., with a cross-encoder) and keep top-k; better context for the FM."
      },
      { mode: "exam", topic: "Agents",
        q: "Orchestration in a Bedrock Agent refers to:",
        options: ["Only streaming", "Coordinating model calls, retrieval, and tool use in a loop", "Only one action", "Only logging"],
        correct: 1,
        explain: "Orchestration = agent loop: reason, retrieve (if KB), call tools, reason again until final response."
      },
      { mode: "exam", topic: "Guardrails",
        q: "Sensitive content filters in Guardrails typically cover:",
        options: ["Only topics", "Hate, violence, sexual content, insults, etc. (configurable)", "Only PII", "Only words"],
        correct: 1,
        explain: "Content filters = hate, violence, sexual, insults, etc.; set threshold (none, low, medium, high) or block."
      },
      { mode: "exam", topic: "Monitoring",
        q: "Evaluating a GenAI application in production should include:",
        options: ["Only latency", "Relevance, safety, and user feedback (and latency/cost)", "Only cost", "Only token count"],
        correct: 1,
        explain: "Evaluate quality (relevance, correctness), safety (guardrails), and operational metrics (latency, cost)."
      },
      { mode: "exam", topic: "Bedrock",
        q: "Batch inference in Bedrock is suited for:",
        options: ["Only real-time chat", "Large volumes of non-urgent requests (e.g., overnight processing)", "Only streaming", "Only single request"],
        correct: 1,
        explain: "Batch = process many inputs asynchronously; lower priority, cost-effective for bulk workloads."
      },
      { mode: "exam", topic: "RAG",
        q: "Source attribution in RAG responses helps with:",
        options: ["Only cost", "Showing which documents supported the answer (trust, compliance)", "Only latency", "Only embedding"],
        correct: 1,
        explain: "Source attribution = cite retrieved chunks; improves trust and allows users to verify."
      },
      { mode: "exam", topic: "Security",
        q: "Data sent to Bedrock for inference:",
        options: ["Is always stored by AWS for training", "Is not used to train AWS models (by default; check data governance)", "Is only in CloudWatch", "Is only in Guardrails"],
        correct: 1,
        explain: "AWS does not use your inference data to train foundation models; review data governance and compliance docs."
      },
      { mode: "exam", topic: "Deployment",
        q: "Containerizing a GenAI app that calls Bedrock allows:",
        options: ["Only Lambda", "Consistent runtime and deployment (e.g., ECS, EKS, SageMaker)", "Only EC2", "Only serverless"],
        correct: 1,
        explain: "Containers = portable; run on ECS, EKS, SageMaker, or Lambda (container support) for consistent deployment."
      },
      { mode: "exam", topic: "Cost",
        q: "Prompt caching (e.g., for repeated system prompts) in Bedrock can reduce:",
        options: ["Only latency", "Input token cost and latency for repeated prefix", "Only output tokens", "Only storage"],
        correct: 1,
        explain: "Caching repeated prompt prefix = fewer input tokens billed and faster inference for the cached part."
      },
      // === TRIPLED BANK: BEDROCK ===
      { mode: "comparison", topic: "Bedrock",
        q: "Which Bedrock API is used for embedding text into vectors?",
        options: ["InvokeModel with a text FM", "InvokeModel with an embedding model (e.g., Titan Embeddings)", "Only Converse API", "Only batch API"],
        correct: 1,
        explain: "Embedding models are invoked via InvokeModel; they take text input and return a vector array."
      },
      { mode: "exam", topic: "Bedrock",
        q: "Region availability for Bedrock models means:",
        options: ["All models are in all regions", "You must enable and use models in each region where they are offered", "Only us-east-1 has models", "Region does not matter"],
        correct: 1,
        explain: "Model availability varies by region; enable and invoke in the region where the model is available."
      },
      { mode: "exam", topic: "Bedrock",
        q: "What is the main benefit of using the Converse API instead of raw InvokeModel for chat?",
        options: ["Lower cost", "Simpler message format and built-in support for multi-turn, tools, and streaming", "Faster only", "Only for batch"],
        correct: 1,
        explain: "Converse API uses a unified message format and handles history, tools, and streaming more easily."
      },
      { mode: "comparison", topic: "Bedrock",
        q: "Bedrock On-Demand Inference differs from Provisioned Throughput in that:",
        options: ["On-Demand requires a contract", "On-Demand has no capacity to reserve; you pay per token", "On-Demand is only for batch", "There is no difference"],
        correct: 1,
        explain: "On-Demand = pay per use, no commitment; Provisioned = reserve capacity for predictable throughput."
      },
      { mode: "exam", topic: "Bedrock",
        q: "When invoking a model with streaming, the client should:",
        options: ["Wait for the full response", "Process response chunks as they arrive for lower perceived latency", "Only use for batch", "Disable Guardrails"],
        correct: 1,
        explain: "Streaming = process chunks as they arrive; improves perceived latency and UX for long answers."
      },
      { mode: "exam", topic: "Bedrock",
        q: "A model alias in Bedrock allows you to:",
        options: ["Only change region", "Point to a specific model version and swap without changing client code", "Only for custom models", "Only for embeddings"],
        correct: 1,
        explain: "Aliases let you pin to a version and update the backing model without changing application code."
      },
      { mode: "exam", topic: "Bedrock",
        q: "Which parameter typically controls randomness in Bedrock text generation?",
        options: ["Only model ID", "Temperature (and optionally top_p, top_k) in inference config", "Only region", "Only timeout"],
        correct: 1,
        explain: "Temperature (and top_p/top_k) control sampling; higher = more random, lower = more deterministic."
      },
      { mode: "exam", topic: "Bedrock",
        q: "Bedrock asynchronous inference is best for:",
        options: ["Single quick requests", "Large or long-running jobs (e.g., summarization of long docs) without blocking", "Only streaming", "Only embeddings"],
        correct: 1,
        explain: "Async = submit job, get result later; good for large inputs or batch-style workloads."
      },
      { mode: "comparison", topic: "Bedrock",
        q: "Amazon Titan Multimodal Embeddings can embed:",
        options: ["Only text", "Text and images (multimodal)", "Only images", "Only audio"],
        correct: 1,
        explain: "Titan Multimodal Embeddings = embed both text and images for multimodal RAG or search."
      },
      { mode: "exam", topic: "Bedrock",
        q: "To reduce latency for repeated prompts, you can use:",
        options: ["Only larger models", "Prompt caching (cache common prefix) where supported", "Only batch", "Only async"],
        correct: 1,
        explain: "Prompt caching stores a repeated prefix; subsequent requests reuse it for lower latency and cost."
      },
      // === TRIPLED: RAG ===
      { mode: "exam", topic: "RAG",
        q: "A Knowledge Base data source can be:",
        options: ["Only DynamoDB", "S3, or other supported connectors (e.g., web crawler)", "Only RDS", "Only Lambda"],
        correct: 1,
        explain: "Knowledge Bases support S3 and other data sources; sync and chunk during ingestion."
      },
      { mode: "exam", topic: "RAG",
        q: "Number of documents retrieved (top-k) in RAG affects:",
        options: ["Only cost", "Relevance and context size (too few = missing context; too many = noise)", "Only latency", "Only embedding model"],
        correct: 1,
        explain: "Top-k = how many chunks to pass to the model; tune for relevance vs. context window and noise."
      },
      { mode: "comparison", topic: "RAG",
        q: "Semantic chunking vs. fixed-size chunking:",
        options: ["Only fixed-size is supported", "Semantic respects boundaries (e.g., paragraphs); fixed-size is simpler", "Only semantic", "They are the same"],
        correct: 1,
        explain: "Semantic = split by meaning/paragraphs; fixed-size = by character/token count; both have tradeoffs."
      },
      { mode: "exam", topic: "RAG",
        q: "To improve RAG answer quality when retrieval returns irrelevant chunks, you should:",
        options: ["Only use a larger model", "Improve chunking, embeddings, or add re-ranking/metadata filters", "Only increase top-k", "Only use one chunk"],
        correct: 1,
        explain: "Better chunking, better embeddings, re-ranking, and metadata filters improve retrieval quality."
      },
      { mode: "exam", topic: "RAG",
        q: "Knowledge Base sync (ingestion) can be triggered:",
        options: ["Only manually once", "On a schedule or on-demand (e.g., when S3 data changes)", "Only at deploy time", "Only by Lambda"],
        correct: 1,
        explain: "Ingestion can run on schedule or on-demand; some connectors support event-driven sync."
      },
      { mode: "exam", topic: "RAG",
        q: "Vector similarity search returns chunks that:",
        options: ["Match keywords only", "Are closest in embedding space to the query embedding", "Are random", "Are largest"],
        correct: 1,
        explain: "Similarity search = compare query embedding to stored vectors; return nearest neighbors."
      },
      { mode: "exam", topic: "RAG",
        q: "Using the same embedding model at ingest and query time is important because:",
        options: ["It reduces cost only", "Embeddings must be in the same space for meaningful similarity", "Only for speed", "Only for Guardrails"],
        correct: 1,
        explain: "Query and document embeddings must come from the same (or compatible) model for correct similarity."
      },
      { mode: "exam", topic: "RAG",
        q: "RAG hallucination can be reduced by:",
        options: ["Only using a larger model", "Retrieving relevant context and asking the model to cite sources", "Only increasing temperature", "Only using one document"],
        correct: 1,
        explain: "Strong retrieval + source attribution and “answer only from context” prompts reduce hallucination."
      },
      { mode: "comparison", topic: "RAG",
        q: "OpenSearch Serverless as a vector store for Knowledge Bases provides:",
        options: ["Only keyword search", "Vector search and optionally hybrid (keyword + vector)", "Only logging", "Only caching"],
        correct: 1,
        explain: "OpenSearch Serverless supports vector and hybrid search for RAG."
      },
      { mode: "exam", topic: "RAG",
        q: "A RAG pipeline typically sends to the FM:",
        options: ["Only the user question", "User question plus retrieved context (e.g., in system or user message)", "Only embeddings", "Only metadata"],
        correct: 1,
        explain: "Prompt = user question + retrieved text as context so the model can ground its answer."
      },
      // === TRIPLED: AGENTS ===
      { mode: "exam", topic: "Agents",
        q: "An agent's action group is linked to:",
        options: ["Only the Knowledge Base", "An OpenAPI schema and a Lambda or API endpoint", "Only streaming", "Only one model"],
        correct: 1,
        explain: "Action group = OpenAPI schema (parameters, paths) + Lambda or API backend for the agent to call."
      },
      { mode: "exam", topic: "Agents",
        q: "When the agent decides to call a tool, it:",
        options: ["Ignores the result", "Sends the tool result back to the model for the next reasoning step", "Only logs it", "Only streams it"],
        correct: 1,
        explain: "Tool output is fed back into the model so it can reason and optionally call more tools or respond."
      },
      { mode: "comparison", topic: "Agents",
        q: "Bedrock Agent vs. single InvokeModel call:",
        options: ["No difference", "Agent can do multi-step reasoning, retrieval, and tool use", "Only Agent streams", "Only InvokeModel supports tools"],
        correct: 1,
        explain: "Agents orchestrate multiple steps (reason, retrieve, call tools); single invoke is one call."
      },
      { mode: "exam", topic: "Agents",
        q: "Agent versioning and aliases help with:",
        options: ["Only cost", "Promoting a tested agent version (e.g., DRAFT to LIVE) without code change", "Only logging", "Only streaming"],
        correct: 1,
        explain: "Version and alias let you test in DRAFT then point LIVE to the new version for safe rollout."
      },
      { mode: "exam", topic: "Agents",
        q: "If an action group Lambda throws an error, the agent typically:",
        options: ["Ignores it", "Receives the error and can reason or retry or inform the user", "Only stops", "Only logs"],
        correct: 1,
        explain: "Tool errors are returned to the model; it can adapt the response or try another action."
      },
      { mode: "exam", topic: "Agents",
        q: "Agent instructions (system prompt) should include:",
        options: ["Only the model name", "Role, constraints, and how to use tools and knowledge", "Only action group names", "Only region"],
        correct: 1,
        explain: "Instructions define the agent's role, rules, and how to use tools/KB for consistent behavior."
      },
      { mode: "exam", topic: "Agents",
        q: "Prepared data sources for an agent refer to:",
        options: ["Only Lambda", "Knowledge Bases (or other data sources) the agent can query", "Only S3", "Only APIs"],
        correct: 1,
        explain: "Prepared data sources = Knowledge Bases (or similar) attached to the agent for retrieval."
      },
      { mode: "exam", topic: "Agents",
        q: "To limit what an agent can do, you should:",
        options: ["Only use one model", "Restrict action groups and use Guardrails + instructions", "Only use streaming", "Only use one Knowledge Base"],
        correct: 1,
        explain: "Limit tools (action groups), scope instructions, and apply Guardrails to keep agent in bounds."
      },
      { mode: "comparison", topic: "Agents",
        q: "Agentic workflow means:",
        options: ["Only one API call", "The agent autonomously plans and uses tools/KB over multiple steps", "Only batch", "Only streaming"],
        correct: 1,
        explain: "Agentic = agent decides when to retrieve, call tools, and respond over multiple turns."
      },
      // === TRIPLED: GUARDRAILS ===
      { mode: "exam", topic: "Guardrails",
        q: "Applying a guardrail at both input and output:",
        options: ["Only at output is allowed", "Filters prompt and response (e.g., block harmful input and output)", "Only at input", "Only for PII"],
        correct: 1,
        explain: "You can apply guardrails to input only, output only, or both for full coverage."
      },
      { mode: "exam", topic: "Guardrails",
        q: "Guardrail content filter thresholds (e.g., for violence) let you:",
        options: ["Only block everything", "Set none/low/medium/high to tune sensitivity", "Only allow everything", "Only for topics"],
        correct: 1,
        explain: "Thresholds control how sensitive the filter is; higher = more strict."
      },
      { mode: "comparison", topic: "Guardrails",
        q: "Denied topics in a guardrail:",
        options: ["Only log", "Cause the guardrail to block or filter content about those topics", "Only at input", "Only for PII"],
        correct: 1,
        explain: "Denied topics = content matching those topics can be blocked or filtered."
      },
      { mode: "exam", topic: "Guardrails",
        q: "To redact PII in model output before showing the user, you use:",
        options: ["Only encryption", "Guardrails PII filter with redact action", "Only IAM", "Only VPC"],
        correct: 1,
        explain: "Guardrails PII filter can detect and redact (e.g., mask) PII in input/output."
      },
      { mode: "exam", topic: "Guardrails",
        q: "Guardrails can be attached to:",
        options: ["Only one model", "Bedrock model invocations and/or agents (configurable per use case)", "Only agents", "Only Knowledge Base"],
        correct: 1,
        explain: "Guardrails are applied when invoking models or when using agents; attach per flow."
      },
      { mode: "exam", topic: "Guardrails",
        q: "Blocked word lists in Guardrails:",
        options: ["Only log", "Block input or output containing those phrases", "Only for topics", "Only at ingest"],
        correct: 1,
        explain: "Word filters = block (or replace) specific words/phrases in content."
      },
      { mode: "exam", topic: "Guardrails",
        q: "Allowed topics in a guardrail:",
        options: ["Only log", "Restrict conversation to only those topics; other content can be blocked", "Only for PII", "Only at output"],
        correct: 1,
        explain: "Allowed topics = allowlist; content outside can be blocked to keep the model on-topic."
      },
      { mode: "comparison", topic: "Guardrails",
        q: "Using multiple guardrails (e.g., one for PII, one for content):",
        options: ["Not supported", "Supported; you can chain or apply multiple guardrails", "Only one guardrail per account", "Only for agents"],
        correct: 1,
        explain: "You can use multiple guardrails for different concerns (PII, content, topics)."
      },
      { mode: "exam", topic: "Guardrails",
        q: "Guardrail versioning allows:",
        options: ["Only one version", "Test changes (e.g., new version) before promoting to production", "Only for word filters", "Only for topics"],
        correct: 1,
        explain: "Create new versions of a guardrail, test, then point invocations to the new version."
      },
      // === TRIPLED: SECURITY ===
      { mode: "exam", topic: "Security",
        q: "To ensure Bedrock traffic does not go over the public internet, use:",
        options: ["Only IAM", "VPC endpoint for Bedrock (private DNS) so traffic stays in AWS", "Only Guardrails", "Only KMS"],
        correct: 1,
        explain: "VPC endpoint + private DNS = Bedrock calls stay on the AWS network, not internet."
      },
      { mode: "exam", topic: "Security",
        q: "Customer-managed keys (CMK) for Bedrock encryption:",
        options: ["Not supported", "Allow you to control key lifecycle and access in KMS", "Only for S3", "Only for agents"],
        correct: 1,
        explain: "You can use a CMK in KMS for Bedrock encryption at rest; you manage key policy."
      },
      { mode: "exam", topic: "Security",
        q: "Least privilege for Bedrock usually means:",
        options: ["Grant bedrock:* to all", "IAM policies that allow only needed actions (e.g., InvokeModel for specific models)", "Only VPC", "Only Guardrails"],
        correct: 1,
        explain: "Limit IAM to specific models and actions (e.g., invoke only required model IDs)."
      },
      { mode: "comparison", topic: "Security",
        q: "PrivateLink for Bedrock enables:",
        options: ["Only public access", "Private connectivity from your VPC to Bedrock without internet", "Only cross-account", "Only logging"],
        correct: 1,
        explain: "PrivateLink = private endpoint in your VPC; traffic stays within AWS network."
      },
      { mode: "exam", topic: "Security",
        q: "To audit who invoked which Bedrock model, use:",
        options: ["Only Guardrails", "CloudTrail (Bedrock API calls are logged)", "Only X-Ray", "Only CloudWatch"],
        correct: 1,
        explain: "CloudTrail logs API calls (who, what, when) for audit and compliance."
      },
      { mode: "exam", topic: "Security",
        q: "Data residency for Bedrock inference:",
        options: ["Data always leaves the region", "Data stays in the region where you invoke (by design)", "Only in us-east-1", "Only with CMK"],
        correct: 1,
        explain: "Invoke in the region where you need residency; data is processed in that region."
      },
      { mode: "exam", topic: "Security",
        q: "Service control policies (SCPs) can restrict Bedrock:",
        options: ["Only in one account", "Across an OU (e.g., deny Bedrock in certain accounts)", "Only for IAM", "Only for VPC"],
        correct: 1,
        explain: "SCPs in Organizations can allow/deny Bedrock (or regions) for member accounts."
      },
      { mode: "exam", topic: "Security",
        q: "To allow a Lambda in account A to invoke Bedrock in account B:",
        options: ["Only IAM in A", "Resource policy on Bedrock in B allowing A + IAM in A allowing invoke", "Only VPC peering", "Only Guardrails"],
        correct: 1,
        explain: "Cross-account: resource policy on Bedrock (B) allows A; IAM in A allows Lambda to call Bedrock."
      },
      { mode: "comparison", topic: "Security",
        q: "Bedrock and PCI-DSS:",
        options: ["Bedrock is never used for PCI", "Use encryption, VPC, IAM, Guardrails; validate with AWS compliance docs", "Only encryption", "Only Guardrails"],
        correct: 1,
        explain: "Use security controls and refer to AWS compliance documentation for PCI scope."
      },
      // === TRIPLED: DEPLOYMENT ===
      { mode: "exam", topic: "Deployment",
        q: "API Gateway in front of Lambda that calls Bedrock helps with:",
        options: ["Only cost", "Throttling, auth, and a stable API for clients", "Only streaming", "Only batch"],
        correct: 1,
        explain: "API Gateway = rate limiting, API keys/auth, and a single endpoint for your GenAI API."
      },
      { mode: "exam", topic: "Deployment",
        q: "For inference that exceeds Lambda timeout, use:",
        options: ["Only Lambda", "Step Functions + Lambda (or ECS/Fargate) to orchestrate long runs", "Only API Gateway", "Only on-demand"],
        correct: 1,
        explain: "Step Functions can orchestrate multi-step or long-running inference beyond Lambda limits."
      },
      { mode: "comparison", topic: "Deployment",
        q: "SageMaker vs. Bedrock for GenAI:",
        options: ["No difference", "Bedrock = managed FMs; SageMaker = bring your own model, fine-tune, full control", "Only SageMaker has streaming", "Only Bedrock has embeddings"],
        correct: 1,
        explain: "Bedrock = managed multi-tenant FMs; SageMaker = your infrastructure, your model, more control."
      },
      { mode: "exam", topic: "Deployment",
        q: "To A/B test two models in production, you can:",
        options: ["Only deploy one", "Route a percentage of traffic to each model (e.g., Lambda or API Gateway)", "Only use batch", "Only use Provisioned Throughput"],
        correct: 1,
        explain: "Route by % traffic (e.g., 90% model A, 10% model B) to compare quality or latency."
      },
      { mode: "exam", topic: "Deployment",
        q: "Infrastructure as Code for a Bedrock-based app might include:",
        options: ["Only Bedrock console", "Terraform or CloudFormation for Lambda, API Gateway, IAM, Bedrock access", "Only IAM", "Only CloudWatch"],
        correct: 1,
        explain: "Define API Gateway, Lambda, IAM roles, and Bedrock permissions in IaC for reproducibility."
      },
      { mode: "exam", topic: "Deployment",
        q: "Cold start for Lambda calling Bedrock is reduced by:",
        options: ["Only increasing memory", "Provisioned concurrency or keeping Lambda warm (e.g., periodic pings)", "Only streaming", "Only batch"],
        correct: 1,
        explain: "Provisioned concurrency or warm-up keeps runtimes ready; reduces cold start latency."
      },
      { mode: "exam", topic: "Deployment",
        q: "To run your own fine-tuned model (e.g., from SageMaker) in production, you would typically:",
        options: ["Only use Bedrock", "Deploy on SageMaker real-time endpoint or in a container (ECS/EKS)", "Only Lambda", "Only Knowledge Base"],
        correct: 1,
        explain: "Custom/fine-tuned models run on SageMaker endpoints or in your own containers."
      },
      { mode: "exam", topic: "Deployment",
        q: "Canary deployment for a GenAI API means:",
        options: ["Only one version", "Route a small % of traffic to new version, then increase if healthy", "Only batch", "Only async"],
        correct: 1,
        explain: "Canary = send a fraction of traffic to new version; monitor; then roll out fully."
      },
      { mode: "comparison", topic: "Deployment",
        q: "When to use ECS/Fargate vs. Lambda for Bedrock invocation:",
        options: ["Always Lambda", "Lambda for event-driven, short runs; ECS for long-running or stateful workers", "Always ECS", "Only for batch"],
        correct: 1,
        explain: "Lambda = event-driven, < 15 min; ECS = long-running, more control, stateful."
      },
      // === TRIPLED: COST ===
      { mode: "exam", topic: "Cost",
        q: "Input tokens are typically cheaper than output tokens for many Bedrock models because:",
        options: ["They are the same", "Generation (output) is more compute-intensive", "Only output is billed", "Only for streaming"],
        correct: 1,
        explain: "Output token pricing is often higher than input; check the model's pricing page."
      },
      { mode: "exam", topic: "Cost",
        q: "To minimize cost for a high-volume, steady workload, consider:",
        options: ["Only on-demand", "Provisioned Throughput if committed use is cheaper than on-demand", "Only serverless", "Only batch"],
        correct: 1,
        explain: "At high, steady volume, Provisioned Throughput can be more cost-effective than on-demand."
      },
      { mode: "comparison", topic: "Cost",
        q: "Token counting before calling Bedrock helps with:",
        options: ["Only latency", "Cost estimation and staying under context limits", "Only streaming", "Only batch"],
        correct: 1,
        explain: "Count tokens to estimate cost and avoid exceeding model context window."
      },
      { mode: "exam", topic: "Cost",
        q: "Using a smaller context window when possible:",
        options: ["Only increases cost", "Reduces cost (fewer input tokens) and can reduce latency", "Only for batch", "Only for streaming"],
        correct: 1,
        explain: "Send only needed context to reduce input tokens and cost."
      },
      { mode: "exam", topic: "Cost",
        q: "Reserved capacity or committed use for Bedrock:",
        options: ["Not available", "Provisioned Throughput provides committed capacity (model units) with pricing terms", "Only for Lambda", "Only for SageMaker"],
        correct: 1,
        explain: "Provisioned Throughput = commit to model units; can have discount vs. on-demand at scale."
      },
      { mode: "exam", topic: "Cost",
        q: "Cost allocation for Bedrock by project is easier with:",
        options: ["Only one IAM user", "Tags on resources and IAM roles (and Cost Allocation Tags)", "Only Guardrails", "Only VPC"],
        correct: 1,
        explain: "Tag roles/resources and enable cost allocation tags to attribute Bedrock cost by project."
      },
      { mode: "exam", topic: "Cost",
        q: "Stopping unnecessary inference (e.g., duplicate or invalid requests) helps:",
        options: ["Only latency", "Cost and latency (fewer tokens billed)", "Only accuracy", "Only security"],
        correct: 1,
        explain: "Validate and deduplicate before calling Bedrock to avoid wasting tokens."
      },
      { mode: "exam", topic: "Cost",
        q: "Bedrock model pricing varies by:",
        options: ["Only region", "Model (provider and size) and often input vs. output tokens", "Only account", "Only invocation type"],
        correct: 1,
        explain: "Each model has its own price per token (input/output); compare models for cost."
      },
      { mode: "comparison", topic: "Cost",
        q: "For a proof-of-concept with low traffic, the most cost-effective option is usually:",
        options: ["Provisioned Throughput", "On-Demand or Serverless (pay per use, no commitment)", "Only batch", "Only custom model"],
        correct: 1,
        explain: "POC = low volume; on-demand/serverless avoids upfront commitment."
      },
      // === TRIPLED: MONITORING ===
      { mode: "exam", topic: "Monitoring",
        q: "Key metrics to monitor for a Bedrock-based API include:",
        options: ["Only cost", "Latency, error rate, token usage, and throttling", "Only tokens", "Only Guardrails"],
        correct: 1,
        explain: "Monitor InvocationLatency, errors, token counts, and throttles for health and cost."
      },
      { mode: "exam", topic: "Monitoring",
        q: "To detect when a model response is off-topic or low quality, you can:",
        options: ["Only use more tokens", "Log inputs/outputs (redacted) and use evaluation or Guardrails metrics", "Only use one model", "Only use batch"],
        correct: 1,
        explain: "Evaluate outputs (relevance, safety) and use Guardrails; log for analysis (with PII redaction)."
      },
      { mode: "comparison", topic: "Monitoring",
        q: "X-Ray tracing for a GenAI request can show:",
        options: ["Only Bedrock", "API Gateway → Lambda → Bedrock and latency per segment", "Only Lambda", "Only errors"],
        correct: 1,
        explain: "X-Ray traces the full request path and segment latency across services."
      },
      { mode: "exam", topic: "Monitoring",
        q: "CloudWatch Logs for Bedrock invocations:",
        options: ["Always log full prompts by default", "Can be enabled; ensure PII/sensitive data is not logged or is redacted", "Only for batch", "Only for agents"],
        correct: 1,
        explain: "Logging can include request/response; redact or restrict for compliance."
      },
      { mode: "exam", topic: "Monitoring",
        q: "To set an alarm when Bedrock error rate exceeds a threshold, use:",
        options: ["Only X-Ray", "CloudWatch alarm on Bedrock metrics (e.g., InvocationClientError)", "Only Guardrails", "Only CloudTrail"],
        correct: 1,
        explain: "Create a CloudWatch alarm on the appropriate Bedrock metric (e.g., client errors)."
      },
      { mode: "exam", topic: "Monitoring",
        q: "Evaluating RAG quality might include:",
        options: ["Only latency", "Relevance of retrieved chunks and faithfulness of the answer to context", "Only token count", "Only cost"],
        correct: 1,
        explain: "Measure retrieval relevance and whether the answer is grounded in the retrieved context."
      },
      { mode: "exam", topic: "Monitoring",
        q: "A/B test results for two models should compare:",
        options: ["Only cost", "Quality (e.g., relevance), latency, and cost", "Only latency", "Only tokens"],
        correct: 1,
        explain: "Compare quality metrics, latency, and cost to choose the best model or prompt."
      },
      { mode: "exam", topic: "Monitoring",
        q: "Dashboard for a production GenAI app should include:",
        options: ["Only score", "Request count, latency (p50/p99), error rate, token usage, cost", "Only Guardrails", "Only model ID"],
        correct: 1,
        explain: "Operational dashboard = traffic, latency, errors, tokens, and cost for capacity and health."
      },
      { mode: "comparison", topic: "Monitoring",
        q: "Bedrock throttling (rate limits) means:",
        options: ["Only cost", "Requests may be limited per second; use exponential backoff or Provisioned Throughput", "Only for batch", "Only for streaming"],
        correct: 1,
        explain: "Bedrock has TPS limits; handle throttling with backoff or reserve capacity with Provisioned Throughput."
      },
    ];
